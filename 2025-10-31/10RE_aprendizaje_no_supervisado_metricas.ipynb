{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c6e5a59",
   "metadata": {},
   "source": [
    "# 10RE - Práctica de Métricas en Aprendizaje No Supervisado\n",
    "\n",
    "En este notebook pondrás en práctica las métricas más importantes para evaluar el clustering, usando los datasets **abalone.csv** y **student_exam_score.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064870c",
   "metadata": {},
   "source": [
    "## ¿Qué aprenderás aquí?\n",
    "- Cómo aplicar el método del codo y entender la inercia.\n",
    "- Cómo interpretar el coeficiente de silueta.\n",
    "- Qué significan las métricas Davies-Bouldin y Calinski-Harabasz.\n",
    "- Cómo comparar y justificar el número óptimo de clústeres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eeae3d",
   "metadata": {},
   "source": [
    "## 1. Cargar y preparar los datos\n",
    "Trabajaremos con los archivos abalone.csv y student_exam_score.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ffa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datasets\n",
    "abalone = pd.read_csv('abalone.csv')\n",
    "student = pd.read_csv('student_exam_scores.csv')\n",
    "\n",
    "# Seleccionar solo variables numéricas\n",
    "abalone_num = abalone.select_dtypes(include=[np.number])\n",
    "student_num = student.select_dtypes(include=[np.number])\n",
    "\n",
    "# Escalar\n",
    "scaler_abalone = StandardScaler()\n",
    "X_abalone = scaler_abalone.fit_transform(abalone_num)\n",
    "\n",
    "scaler_student = StandardScaler()\n",
    "X_student = scaler_student.fit_transform(student_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e1575",
   "metadata": {},
   "source": [
    "## 2. Método del Codo (Elbow)\n",
    "El método del codo nos ayuda a elegir el número de clústeres adecuado. La inercia mide lo juntos que están los puntos en cada grupo. Buscamos el 'codo' en la gráfica, donde la inercia deja de bajar rápidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47238892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow(X, title):\n",
    "    inertias = []\n",
    "    for k in range(1, 11):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "    plt.plot(range(1, 11), inertias, marker='o')\n",
    "    plt.xlabel('Número de clústeres')\n",
    "    plt.ylabel('Inercia')\n",
    "    plt.title(f'Método del codo {title}')\n",
    "    plt.show()\n",
    "\n",
    "plot_elbow(X_abalone, 'Abalone')\n",
    "plot_elbow(X_student, 'Student Exam Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4dc28b",
   "metadata": {},
   "source": [
    "**¿Qué debes observar?**\n",
    "Busca el punto donde la curva de inercia cambia de pendiente bruscamente. Ese es el número óptimo de clústeres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea0661",
   "metadata": {},
   "source": [
    "## 3. Silhouette Score\n",
    "El coeficiente de silueta mide lo bien agrupado que está cada punto. Si es cercano a 1, el punto está bien en su grupo. Si es cercano a 0, está entre dos grupos. Si es negativo, está mal clasificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a998f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_scores(X, title):\n",
    "    scores = []\n",
    "    for k in range(2, 11):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        scores.append(score)\n",
    "    plt.plot(range(2, 11), scores, marker='o')\n",
    "    plt.xlabel('Número de clústeres')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title(f'Silhouette Score {title}')\n",
    "    plt.show()\n",
    "\n",
    "plot_silhouette_scores(X_abalone, 'Abalone')\n",
    "plot_silhouette_scores(X_student, 'Student Exam Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761cdc2",
   "metadata": {},
   "source": [
    "**¿Qué debes observar?**\n",
    "Elige el número de clústeres donde el Silhouette Score sea más alto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436e341",
   "metadata": {},
   "source": [
    "## 4. Davies-Bouldin y Calinski-Harabasz\n",
    "Estas métricas también ayudan a comparar la calidad de los clústeres. Davies-Bouldin debe ser lo más bajo posible. Calinski-Harabasz, lo más alto posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_db_ch(X, title):\n",
    "    db_scores = []\n",
    "    ch_scores = []\n",
    "    for k in range(2, 11):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        db_scores.append(davies_bouldin_score(X, labels))\n",
    "        ch_scores.append(calinski_harabasz_score(X, labels))\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(range(2, 11), db_scores, 'r-o', label='Davies-Bouldin (bajo=mejor)')\n",
    "    ax1.set_xlabel('Número de clústeres')\n",
    "    ax1.set_ylabel('Davies-Bouldin', color='r')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(2, 11), ch_scores, 'b-o', label='Calinski-Harabasz (alto=mejor)')\n",
    "    ax2.set_ylabel('Calinski-Harabasz', color='b')\n",
    "    plt.title(f'Davies-Bouldin y Calinski-Harabasz {title}')\n",
    "    plt.show()\n",
    "\n",
    "plot_db_ch(X_abalone, 'Abalone')\n",
    "plot_db_ch(X_student, 'Student Exam Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da126c",
   "metadata": {},
   "source": [
    "## 5. Práctica final\n",
    "Elige el mejor número de clústeres para cada dataset y justifica tu elección usando las métricas anteriores.\n",
    "\n",
    "- ¿Coinciden todas las métricas en el mismo número de clústeres?\n",
    "- ¿Qué diferencias observas entre los dos datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f93b5d",
   "metadata": {},
   "source": [
    "**Reflexión sobre los resultados en Student Exam Score:**\n",
    "\n",
    "En este caso, la mayoría de las métricas (Silhouette Score y Davies-Bouldin) indican que el número óptimo de clústeres es **2**. Sin embargo, la métrica Calinski-Harabasz muestra su valor máximo en **9** clústeres.\n",
    "\n",
    "Esto puede ocurrir porque Calinski-Harabasz a veces favorece valores altos de clústeres, especialmente si los datos tienen pocos puntos o los grupos no son muy compactos. Por el contrario, Silhouette y Davies-Bouldin suelen ser más fiables porque consideran tanto la cohesión interna como la separación entre grupos.\n",
    "\n",
    "**Conclusión:**\n",
    "Me quedo con **2 clústeres** como la mejor opción para este dataset, ya que está respaldado por la mayoría de las métricas y tiene más sentido práctico. Es importante comparar varias métricas y no basarse solo en una para tomar la decisión final."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
