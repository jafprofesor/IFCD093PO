{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0ea28c",
   "metadata": {},
   "source": [
    "# üìè M√≥dulo 3.2: M√©tricas en Aprendizaje No Supervisado\n",
    "### Curso: **Machine Learning con Python** (IFCD093PO)\n",
    "**Duraci√≥n estimada:** 4 horas\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos del M√≥dulo\n",
    "\n",
    "En el m√≥dulo anterior, descubrimos el mundo del aprendizaje no supervisado. Pero una pregunta qued√≥ en el aire: **¬øc√≥mo sabemos si nuestros resultados son buenos?** Este m√≥dulo se dedica a responder esa pregunta, proporcion√°ndote las herramientas para evaluar la calidad de tus modelos de clustering.\n",
    "\n",
    "Al finalizar, ser√°s capaz de:\n",
    "\n",
    "- ‚úÖ Comprender la diferencia entre evaluaci√≥n **extr√≠nseca** (con etiquetas) e **intr√≠nseca** (sin etiquetas).\n",
    "- ‚úÖ Aplicar e interpretar el **M√©todo del Codo (Elbow Method)** para estimar el n√∫mero √≥ptimo de cl√∫steres.\n",
    "- ‚úÖ Calcular e interpretar el **Coeficiente de Silueta**, una de las m√©tricas m√°s importantes para evaluar la cohesi√≥n y separaci√≥n de los cl√∫steres.\n",
    "- ‚úÖ Utilizar otras m√©tricas intr√≠nsecas como el **√çndice de Davies-Bouldin** y el **√çndice de Calinski-Harabasz**.\n",
    "- ‚úÖ Tomar decisiones informadas sobre el n√∫mero de cl√∫steres (`k`) bas√°ndote en evidencia cuantitativa.\n",
    "\n",
    "**¬°Prep√°rate para a√±adir rigor cient√≠fico a tu exploraci√≥n de datos y validar los patrones que descubras!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a609b",
   "metadata": {},
   "source": [
    "## üìö Tabla de Contenidos\n",
    "\n",
    "1. [El Desaf√≠o de la Evaluaci√≥n](#1-desafio)\n",
    "2. [Preparaci√≥n de Datos para Evaluaci√≥n](#2-preparacion)\n",
    "3. [M√©todo del Codo (Elbow Method)](#3-codo)\n",
    "   - [Inercia: El Concepto Clave](#3.1-inercia)\n",
    "   - [Implementaci√≥n y Visualizaci√≥n](#3.2-implementacion-codo)\n",
    "4. [Coeficiente de Silueta](#4-silueta)\n",
    "   - [Intuici√≥n: Cohesi√≥n vs. Separaci√≥n](#4.1-intuicion-silueta)\n",
    "   - [C√°lculo e Interpretaci√≥n](#4.2-calculo-silueta)\n",
    "   - [Visualizaci√≥n de Siluetas](#4.3-visualizacion-silueta)\n",
    "5. [Otras M√©tricas Intr√≠nsecas](#5-otras-metricas)\n",
    "   - [√çndice de Davies-Bouldin](#5.1-davies-bouldin)\n",
    "   - [√çndice de Calinski-Harabasz](#5.2-calinski-harabasz)\n",
    "6. [Comparando M√©tricas: ¬øCu√°l Usar?](#6-comparando)\n",
    "7. [Resumen y Pr√≥ximos Pasos](#7-resumen)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e2135",
   "metadata": {},
   "source": [
    "## üßê 1. El Desaf√≠o de la Evaluaci√≥n <a id='1-desafio'></a>\n",
    "\n",
    "Como no tenemos etiquetas `y`, no podemos usar m√©tricas como *accuracy*, *precision* o *recall*. La evaluaci√≥n en aprendizaje no supervisado se divide en dos categor√≠as:\n",
    "\n",
    "- **Evaluaci√≥n Extr√≠nseca**: Se usa cuando, por casualidad, tenemos las etiquetas verdaderas (ground truth), pero no las usamos para el entrenamiento. Es √∫til para comparar algoritmos en un entorno acad√©mico, pero raro en la pr√°ctica. Ejemplos: *Rand Index*, *Homogeneity Score*.\n",
    "\n",
    "- **Evaluaci√≥n Intr√≠nseca**: Es el caso m√°s com√∫n. Se eval√∫a la calidad del clustering bas√°ndose √∫nicamente en la estructura de los datos y los cl√∫steres formados. Se centra en dos conceptos:\n",
    "  - **Cohesi√≥n**: ¬øQu√© tan compactos son los cl√∫steres? (Los puntos dentro de un cl√∫ster deben estar cerca entre s√≠).\n",
    "  - **Separaci√≥n**: ¬øQu√© tan separados est√°n los cl√∫steres entre s√≠? (Los cl√∫steres diferentes deben estar lejos unos de otros).\n",
    "\n",
    "**En este notebook, nos centraremos en las m√©tricas de evaluaci√≥n intr√≠nseca.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74710212",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 2. Preparaci√≥n de Datos para Evaluaci√≥n <a id='2-preparacion'></a>\n",
    "\n",
    "Usaremos un conjunto de datos sint√©tico para poder visualizar y entender f√°cilmente c√≥mo funcionan las m√©tricas. Tambi√©n cargaremos el famoso dataset `iris` para un caso de uso m√°s realista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs, load_iris # Cargar conjuntos de datos\n",
    "from sklearn.cluster import KMeans # Algoritmo de clustering K-Means\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Datos Sint√©ticos ---\n",
    "# Generamos datos con 4 centros bien definidos para que sea f√°cil de evaluar\n",
    "# Parametros:\n",
    "# n_samples: n√∫mero de muestras\n",
    "# n_features: n√∫mero de caracter√≠sticas\n",
    "# centers: n√∫mero de clusters\n",
    "# cluster_std: desviaci√≥n est√°ndar de los clusters\n",
    "X_blobs, y_blobs = make_blobs(n_samples=500, n_features=2, centers=4, cluster_std=0.8, random_state=42)\n",
    "\n",
    "# Es buena pr√°ctica escalar los datos antes del clustering\n",
    "scaler_blobs = StandardScaler()\n",
    "X_blobs_scaled = scaler_blobs.fit_transform(X_blobs)\n",
    "\n",
    "# --- Datos Iris ---\n",
    "# Cargamos el conjunto de datos Iris\n",
    "# Este conjunto tiene 3 clases (tipos de flores) y 4 caracter√≠sticas\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target # Usaremos 'y' solo para comparar al final, no para entrenar\n",
    "\n",
    "scaler_iris = StandardScaler()\n",
    "X_iris_scaled = scaler_iris.fit_transform(X_iris)\n",
    "\n",
    "print(\"Datos sint√©ticos (escalados) shape:\", X_blobs_scaled.shape)\n",
    "print(\"Datos Iris (escalados) shape:\", X_iris_scaled.shape)\n",
    "\n",
    "# Visualicemos los datos sint√©ticos\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_blobs_scaled[:, 0], X_blobs_scaled[:, 1], s=50)\n",
    "plt.title(\"Datos Sint√©ticos para Evaluaci√≥n de Clustering\")\n",
    "plt.xlabel(\"Caracter√≠stica 1 (escalada)\")\n",
    "plt.ylabel(\"Caracter√≠stica 2 (escalada)\")\n",
    "plt.show()\n",
    "# Visualicemos los datos Iris (solo las dos primeras caracter√≠sticas para simplicidad)\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Usamos las dos primeras caracter√≠sticas para visualizaci√≥n\n",
    "# Esto es solo para simplicidad, ya que Iris tiene 4 caracter√≠sticas\n",
    "# En un caso real, podr√≠amos usar t√©cnicas de reducci√≥n de dimensionalidad como PCA o t-SNE\n",
    "# Parametros:\n",
    "# - X: Datos de entrada\n",
    "# - y: Etiquetas verdaderas\n",
    "# - cmap: Mapa de colores\n",
    "# - s: Tama√±o de los puntos\n",
    "# - c: Color basado en las etiquetas verdaderas\n",
    "plt.scatter(X_iris_scaled[:, 0], X_iris_scaled[:, 1], c=y_iris, cmap='viridis', s=50)\n",
    "plt.title(\"Datos Iris (2 primeras caracter√≠sticas)\")\n",
    "plt.xlabel(\"Caracter√≠stica 1 (escalada)\")\n",
    "plt.ylabel(\"Caracter√≠stica 2 (escalada)\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f1faf",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Explicaci√≥n de los gr√°ficos realizados\n",
    "\n",
    "### üìä Explicaci√≥n de los Gr√°ficos Realizados\n",
    "\n",
    "1. **Gr√°fico de Dispersi√≥n de los Datos Sint√©ticos**\n",
    "    - Este gr√°fico muestra los datos generados artificialmente con 4 cl√∫steres bien definidos. Cada punto representa una muestra y se visualizan dos caracter√≠sticas escaladas. Sirve para ver visualmente la estructura de los cl√∫steres antes de aplicar cualquier algoritmo.\n",
    "\n",
    "2. **Gr√°fico de Dispersi√≥n del Dataset Iris**\n",
    "    - Aqu√≠ se muestran las dos primeras caracter√≠sticas del famoso dataset Iris, coloreando los puntos seg√∫n su clase real (`y_iris`). Permite observar c√≥mo se distribuyen las especies de flores en el espacio de caracter√≠sticas.\n",
    "\n",
    "Estos gr√°ficos ayudan a entender visualmente la estructura de los datos y a tomar decisiones informadas sobre el n√∫mero √≥ptimo de cl√∫steres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc2e0e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c0b1a",
   "metadata": {},
   "source": [
    "## üí™ 3. M√©todo del Codo (Elbow Method) <a id='3-codo'></a>\n",
    "\n",
    "Es una de las t√©cnicas m√°s populares y sencillas para estimar el n√∫mero de cl√∫steres. Se basa en el concepto de **inercia**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc96d4",
   "metadata": {},
   "source": [
    "### 3.1 Inercia: El Concepto Clave <a id='3.1-inercia'></a>\n",
    "\n",
    "La inercia mide qu√© tan compactos o \"apretados\" est√°n los grupos (clusters) que ha creado un algoritmo de agrupamiento.\n",
    "\n",
    "**¬øC√≥mo funciona?**\n",
    "\n",
    "Imagina que tienes puntos agrupados y cada grupo tiene un centro (centroide). La inercia funciona as√≠:\n",
    "\n",
    "Para cada punto: calcula su distancia hasta el centro de su grupo.\n",
    "\n",
    "Eleva esa distancia al cuadrado (para que todas sean positivas y penalizar m√°s las distancias grandes).\n",
    "\n",
    "Suma todas esas distancias al cuadrado.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "- Imagina 3 puntos en un grupo cuyo centro est√° en (0,0):\n",
    "\n",
    "    - Punto A est√° a distancia 2 del centro ‚Üí contribuye 2¬≤ = 4\n",
    "\n",
    "    - Punto B est√° a distancia 1 del centro ‚Üí contribuye 1¬≤ = 1\n",
    "\n",
    "    - Punto C est√° a distancia 3 del centro ‚Üí contribuye 3¬≤ = 9\n",
    "\n",
    "    Inercia de este grupo = 4 + 1 + 9 = 14\n",
    "\n",
    "    Si tienes varios grupos, sumas la inercia de todos ellos.\n",
    "\n",
    "**¬øPara qu√© sirve?**\n",
    "\n",
    "- Inercia baja = puntos muy cercanos a sus centros = grupos bien definidos ‚úì\n",
    "\n",
    "- Inercia alta = puntos dispersos lejos de sus centros = grupos poco compactos ‚úó\n",
    "\n",
    "La idea del m√©todo del codo es simple: calculamos la inercia para diferentes n√∫meros de cl√∫steres (`k`). A medida que `k` aumenta, la inercia siempre disminuir√° (en el caso extremo, si cada punto es un cl√∫ster, la inercia es 0). Buscamos el punto donde la disminuci√≥n de la inercia se ralentiza dr√°sticamente, formando un \"codo\" en el gr√°fico. Este punto es un buen candidato para el n√∫mero √≥ptimo de cl√∫steres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b6a29",
   "metadata": {},
   "source": [
    "**En definitiva:**\n",
    "\n",
    "La inercia mide lo ‚Äújuntos‚Äù que est√°n los puntos dentro de cada grupo (cl√∫ster). Es como sumar todas las distancias de los puntos a su centro de grupo.\n",
    "\n",
    "Si la inercia es baja, los puntos est√°n bien agrupados.\n",
    "Si la inercia es alta, los puntos est√°n muy dispersos.\n",
    "\n",
    "En el m√©todo del codo, probamos diferentes n√∫meros de grupos y vemos c√≥mo baja la inercia. \n",
    "\n",
    "El ‚Äúcodo‚Äù del gr√°fico nos dice cu√°ntos grupos son los ideales: es el punto donde dejar de a√±adir m√°s grupos ya no mejora mucho la agrupaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow_method(X, max_k=10):\n",
    "    \"\"\"\n",
    "    Calcula y grafica la inercia para un rango de k y muestra el m√©todo del codo.\n",
    "    \"\"\"\n",
    "    inertias = []\n",
    "    k_range = range(1, max_k + 1)\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "        kmeans.fit(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, inertias, 'bo-')\n",
    "    plt.xlabel('N√∫mero de Cl√∫steres (k)')\n",
    "    plt.ylabel('Inercia (WCSS)')\n",
    "    plt.title('M√©todo del Codo para Encontrar k √ìptimo')\n",
    "    plt.xticks(k_range)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print(\"--- M√©todo del Codo para Datos Sint√©ticos ---\")\n",
    "plot_elbow_method(X_blobs_scaled)\n",
    "\n",
    "print(\"\\n--- M√©todo del Codo para Datos Iris ---\")\n",
    "plot_elbow_method(X_iris_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbe447",
   "metadata": {},
   "source": [
    "**An√°lisis de los Gr√°ficos:**\n",
    "\n",
    "- **Datos Sint√©ticos**: Se observa un \"codo\" muy claro en `k=4`. Despu√©s de este punto, la disminuci√≥n de la inercia es mucho menos pronunciada. Esto sugiere que 4 es el n√∫mero √≥ptimo de cl√∫steres, lo cual coincide con c√≥mo generamos los datos.\n",
    "- **Datos Iris**: El codo es menos pronunciado, pero parece estar en `k=3`. Esto tambi√©n coincide con el n√∫mero real de especies de flores en el dataset.\n",
    "\n",
    "**Limitaci√≥n**: El m√©todo del codo puede ser ambiguo si el \"codo\" no es claro. Por eso, es bueno complementarlo con otras m√©tricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382afba3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c04ef",
   "metadata": {},
   "source": [
    "## üìê 4. Coeficiente de Silueta <a id='4-silueta'></a>\n",
    "\n",
    "El Coeficiente de Silueta es una m√©trica m√°s robusta que mide qu√© tan bien se ajusta cada punto a su propio cl√∫ster en comparaci√≥n con los cl√∫steres vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f260ed2",
   "metadata": {},
   "source": [
    "### 4.1 Intuici√≥n: Cohesi√≥n vs. Separaci√≥n <a id='4.1-intuicion-silueta'></a>\n",
    "\n",
    "Para cada punto de datos, el coeficiente de silueta se calcula as√≠:\n",
    "\n",
    "1.  **`a` (Cohesi√≥n)**: La distancia promedio del punto a todos los dem√°s puntos en el **mismo cl√∫ster**.\n",
    "2.  **`b` (Separaci√≥n)**: La distancia promedio del punto a todos los puntos en el **cl√∫ster m√°s cercano que no es el suyo**.\n",
    "\n",
    "El coeficiente de silueta `s` para un solo punto es:\n",
    "\n",
    "$$ s = \\frac{b - a}{\\max(a, b)} $$\n",
    "\n",
    "El valor de `s` var√≠a entre -1 y 1:\n",
    "- **`s` cercano a +1**: ¬°Excelente! El punto est√° muy bien agrupado. Est√° lejos de los cl√∫steres vecinos (`b` es grande) y cerca de los miembros de su propio cl√∫ster (`a` es peque√±o).\n",
    "- **`s` cercano a 0**: El punto est√° en el borde entre dos cl√∫steres. No est√° claro a cu√°l pertenece.\n",
    "- **`s` cercano a -1**: ¬°Muy mal! El punto probablemente ha sido asignado al cl√∫ster equivocado. Est√° m√°s cerca de un cl√∫ster vecino que del suyo.\n",
    "\n",
    "El **Silhouette Score** para un conjunto de cl√∫steres es simplemente el promedio de los coeficientes de silueta de todos los puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684e15e",
   "metadata": {},
   "source": [
    "**Es decir:**\n",
    "\n",
    "El coeficiente de silueta te dice lo bien que est√° cada punto dentro de su grupo (cl√∫ster):\n",
    "\n",
    "Si el valor es cercano a 1, el punto est√° muy bien en su grupo y lejos de los otros grupos (¬°perfecto!).\n",
    "\n",
    "Si el valor es cercano a 0, el punto est√° entre dos grupos (no est√° claro a cu√°l pertenece).\n",
    "\n",
    "Si el valor es negativo, el punto est√° m√°s cerca de otro grupo que del suyo (probablemente est√° mal clasificado).\n",
    "\n",
    "**En resumen:** cuanto m√°s alto el coeficiente de silueta, mejor agrupado est√° el punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_score(X, max_k=10):\n",
    "    \"\"\"\n",
    "    Calcula y grafica el Silhouette Score para un rango de k.\n",
    "    \"\"\"\n",
    "    silhouette_scores = []\n",
    "    k_range = range(2, max_k + 1) # Silhouette no est√° definido para k=1, por eso empezamos en 2\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "        kmeans.fit(X)\n",
    "        score = silhouette_score(X, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, silhouette_scores, 'go-')\n",
    "    plt.xlabel('N√∫mero de Cl√∫steres (k)')\n",
    "    plt.ylabel('Silhouette Score Promedio')\n",
    "    plt.title('An√°lisis de Silueta para Encontrar k √ìptimo')\n",
    "    plt.xticks(k_range)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print(\"--- An√°lisis de Silueta para Datos Sint√©ticos ---\")\n",
    "plot_silhouette_score(X_blobs_scaled)\n",
    "\n",
    "print(\"\\n--- An√°lisis de Silueta para Datos Iris ---\")\n",
    "plot_silhouette_score(X_iris_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b732dd9",
   "metadata": {},
   "source": [
    "**An√°lisis de los Gr√°ficos:**\n",
    "\n",
    "- **Datos Sint√©ticos**: El Silhouette Score m√°s alto se alcanza en `k=4`. Esto confirma fuertemente el resultado del m√©todo del codo.\n",
    "- **Datos Iris**: El score m√°s alto se da en `k=2`. Esto es interesante y diferente del m√©todo del codo. Muestra que, seg√∫n esta m√©trica, la mejor separaci√≥n se logra al dividir los datos en dos grandes grupos. El score para `k=3` tambi√©n es alto, lo que lo convierte en un candidato viable. Esto resalta la importancia de no depender de una sola m√©trica.\n",
    "\n",
    "**¬øPor qu√© la diferencia en Iris?** El dataset Iris tiene dos especies que son muy similares entre s√≠ y una que es muy distinta. El Silhouette Score para `k=2` probablemente agrupa las dos especies similares y separa la distinta, logrando una separaci√≥n y cohesi√≥n global muy buena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99f7a3",
   "metadata": {},
   "source": [
    "### 4.3 Visualizaci√≥n de Siluetas <a id='4.3-visualizacion-silueta'></a>\n",
    "\n",
    "Podemos ir un paso m√°s all√° y visualizar los coeficientes de silueta para cada punto dentro de cada cl√∫ster. Esto nos da una idea de la \"salud\" de cada cl√∫ster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_silhouette_diagram(X, k):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 7)\n",
    "    \n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    ax1.set_ylim([0, len(X) + (k + 1) * 10])\n",
    "    \n",
    "    y_lower = 10\n",
    "    for i in range(k):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        \n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        \n",
    "        color = cm.nipy_spectral(float(i) / k)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        \n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        y_lower = y_upper + 10\n",
    "        \n",
    "    ax1.set_title(f\"Diagrama de Silueta para k={k}\")\n",
    "    ax1.set_xlabel(\"Coeficiente de Silueta\")\n",
    "    ax1.set_ylabel(\"Cl√∫ster\")\n",
    "    \n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "print(\"--- Diagrama de Silueta para Datos Sint√©ticos con k=4 ---\")\n",
    "plot_silhouette_diagram(X_blobs_scaled, 4)\n",
    "\n",
    "print(\"\\n--- Diagrama de Silueta para Datos Iris con k=2 ---\")\n",
    "plot_silhouette_diagram(X_iris_scaled, 2)\n",
    "\n",
    "print(\"\\n--- Diagrama de Silueta para Datos Iris con k=3 ---\")\n",
    "plot_silhouette_diagram(X_iris_scaled, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782945fe",
   "metadata": {},
   "source": [
    "**An√°lisis de los Diagramas:**\n",
    "\n",
    "- **Datos Sint√©ticos (k=4)**: Todos los cl√∫steres tienen un grosor similar y la mayor√≠a de sus puntos est√°n por encima del promedio (l√≠nea roja). Esto indica un clustering muy bueno y equilibrado.\n",
    "- **Iris (k=2)**: Un cl√∫ster es grande y el otro m√°s peque√±o, pero ambos est√°n claramente por encima del promedio. Es una buena partici√≥n.\n",
    "- **Iris (k=3)**: Se ve que el cl√∫ster 0 es muy bueno (ancho y muy por encima del promedio). Sin embargo, los cl√∫steres 1 y 2 son m√°s estrechos y est√°n m√°s cerca de la l√≠nea promedio. Esto visualiza por qu√© el score para k=3 es bueno, pero no tan alto como para k=2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1abcd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bfaa76",
   "metadata": {},
   "source": [
    "## üìà 5. Otras M√©tricas Intr√≠nsecas <a id='5-otras-metricas'></a>\n",
    "\n",
    "Existen otras m√©tricas que tambi√©n eval√∫an la cohesi√≥n y separaci√≥n, pero con formulaciones matem√°ticas diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b87734",
   "metadata": {},
   "source": [
    "### 5.1 √çndice de Davies-Bouldin <a id='5.1-davies-bouldin'></a>\n",
    "\n",
    "**¬øQu√© mide?**\n",
    "\n",
    "Eval√∫a qu√© tan bien separados est√°n tus grupos comparando cada grupo con su \"vecino m√°s parecido\".\n",
    "\n",
    "**¬øC√≥mo funciona?**\n",
    "\n",
    "Para cada grupo, el √≠ndice hace dos preguntas:\n",
    "\n",
    "-   ¬øQu√© tan compacto es mi grupo? ‚Üí Mide qu√© tan cerca est√°n los puntos de su centro\n",
    "-   ¬øQu√© tan lejos est√° del grupo m√°s cercano? ‚Üí Mide la distancia entre centros\n",
    "\n",
    "**Luego calcula:**\n",
    "\n",
    "    Similitud = (Compacidad grupo A + Compacidad grupo B) / Distancia entre centros\n",
    "\n",
    "**Ejemplo intuitivo**\n",
    "\n",
    "Imagina dos grupos de personas:\n",
    "\n",
    "1. *Escenario 1 (MALO - Davies-Bouldin alto):*\n",
    "\n",
    "- Grupo A: personas muy dispersas (compacidad alta)\n",
    "\n",
    "- Grupo B: muy cerca del Grupo A (distancia baja)\n",
    "\n",
    "Resultado: grupos confusos, mal separados\n",
    "\n",
    "2. *Escenario 2 (BUENO - Davies-Bouldin bajo):*\n",
    "\n",
    "- Grupo A: personas muy juntas (compacidad baja)\n",
    "\n",
    "- Grupo B: muy lejos del Grupo A (distancia alta)\n",
    "\n",
    "Resultado: grupos claros y bien definidos\n",
    "\n",
    "**Interpretaci√≥n**\n",
    "\n",
    "- Valor cercano a 0 = Grupos perfectamente separados ‚úì\n",
    "\n",
    "- Valor alto = Grupos confusos o solapados ‚úó\n",
    "\n",
    "**Ventaja pr√°ctica**\n",
    "\n",
    "Es m√°s r√°pido de calcular que otros √≠ndices como el Silhouette Score, por lo que es √∫til cuando trabajas con muchos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd9c5a",
   "metadata": {},
   "source": [
    "### 5.2 √çndice de Calinski-Harabasz <a id='5.2-calinski-harabasz'></a>\n",
    "\n",
    "**¬øQu√© mide?**\n",
    "\n",
    "Compara qu√© tan separados est√°n los grupos entre s√≠ versus qu√© tan compactos son internamente.\n",
    "\n",
    "**¬øC√≥mo funciona?**\n",
    "\n",
    "Es b√°sicamente una divisi√≥n:\n",
    "\n",
    "    Calinski-Harabasz = Separaci√≥n entre grupos / Compacidad dentro de grupos\n",
    "\n",
    "*Numerador (arriba): ¬øQu√© tan alejados est√°n los centros de los grupos?*\n",
    "\n",
    "*Denominador (abajo): ¬øQu√© tan dispersos est√°n los puntos dentro de cada grupo?*\n",
    "\n",
    "**Ejemplo** \n",
    "\n",
    "Imagina clasificar animales en grupos:\n",
    "\n",
    "1. Escenario 1 (BUENO - valor alto):\n",
    "\n",
    "-   Los gatos est√°n muy juntos entre s√≠ (compacidad baja ‚úì)\n",
    "\n",
    "-   Los perros est√°n muy juntos entre s√≠ (compacidad baja ‚úì)\n",
    "\n",
    "-   Gatos y perros est√°n MUY separados (separaci√≥n alta ‚úì)\n",
    "\n",
    "*Resultado: Valor alto = excelente agrupamiento*\n",
    "\n",
    "2. Escenario 2 (MALO - valor bajo):\n",
    "\n",
    "-   Los gatos est√°n dispersos (compacidad alta ‚úó)\n",
    "\n",
    "-   Los perros est√°n dispersos (compacidad alta ‚úó)\n",
    "\n",
    "-   Gatos y perros est√°n mezclados (separaci√≥n baja ‚úó)\n",
    "\n",
    "*Resultado: Valor bajo = mal agrupamiento*\n",
    "\n",
    "**Interpretaci√≥n**\n",
    "\n",
    "- Valor alto = Grupos densos y bien separados ‚úì\n",
    "\n",
    "- Valor bajo = Grupos dispersos o solapados ‚úó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cfaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_metrics(X, max_k=10):\n",
    "    k_range = range(2, max_k + 1)\n",
    "    results = []\n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        \n",
    "        silhouette = silhouette_score(X, labels)\n",
    "        davies_bouldin = davies_bouldin_score(X, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "        \n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'Silhouette (M√°s alto es mejor)': silhouette,\n",
    "            'Davies-Bouldin (M√°s bajo es mejor)': davies_bouldin,\n",
    "            'Calinski-Harabasz (M√°s alto es mejor)': calinski_harabasz\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).set_index('k')\n",
    "\n",
    "print(\"--- Comparaci√≥n de M√©tricas para Datos Sint√©ticos ---\")\n",
    "results_blobs = compare_all_metrics(X_blobs_scaled)\n",
    "display(results_blobs)\n",
    "\n",
    "print(\"\\n--- Comparaci√≥n de M√©tricas para Datos Iris ---\")\n",
    "results_iris = compare_all_metrics(X_iris_scaled)\n",
    "display(results_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a4fab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f92be",
   "metadata": {},
   "source": [
    "## ü§î 6. Comparando M√©tricas: ¬øCu√°l Usar? <a id='6-comparando'></a>\n",
    "\n",
    "**An√°lisis de las Tablas:**\n",
    "\n",
    "- **Datos Sint√©ticos**: Todas las m√©tricas coinciden. El Silhouette y Calinski-Harabasz tienen su m√°ximo en `k=4`, y el Davies-Bouldin tiene su m√≠nimo en `k=4`. ¬°Consenso total!\n",
    "\n",
    "- **Datos Iris**: Todas las m√©tricas coinciden.\n",
    "  - **Silhouette** prefiere `k=2`.\n",
    "  - **Davies-Bouldin** prefiere `k=2` (su valor m√°s bajo es 0.593).\n",
    "  - **Calinski-Harabasz** prefiere `k=2` (su valor m√°s alto es 251.34).\n",
    "\n",
    "**Conclusi√≥n Pr√°ctica:**\n",
    "\n",
    "1.  **Empieza con el M√©todo del Codo**: Es una primera aproximaci√≥n r√°pida y visual.\n",
    "2.  **Confirma con Silhouette Score**: Es la m√©trica m√°s intuitiva y robusta. Su visualizaci√≥n por cl√∫ster es muy informativa.\n",
    "3.  **Usa Davies-Bouldin y Calinski-Harabasz como desempate o confirmaci√≥n**: Son r√°pidas y pueden ofrecer una perspectiva diferente.\n",
    "4.  **El contexto de negocio es el rey**: Si las m√©tricas no se ponen de acuerdo, la decisi√≥n final debe basarse en qu√© n√∫mero de cl√∫steres tiene m√°s sentido para tu problema. ¬øEs m√°s √∫til para marketing tener 2 segmentos de clientes o 3? La respuesta a esa pregunta puede ser m√°s importante que una d√©cima de diferencia en una m√©trica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bf4e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6baac",
   "metadata": {},
   "source": [
    "## üìù 7. Resumen y Pr√≥ximos Pasos <a id='7-resumen'></a>\n",
    "\n",
    "### üéâ ¬°Ahora puedes medir la calidad de tus descubrimientos!\n",
    "\n",
    "#### ‚úÖ Lo que has aprendido:\n",
    "\n",
    "1. **El Principio Fundamental**\n",
    "   - La evaluaci√≥n intr√≠nseca se basa en la **cohesi√≥n** (qu√© tan juntos est√°n los puntos de un cl√∫ster) y la **separaci√≥n** (qu√© tan lejos est√°n los cl√∫steres entre s√≠).\n",
    "\n",
    "2. **Tus Herramientas de Evaluaci√≥n**\n",
    "   - **M√©todo del Codo**: Una forma visual y r√°pida de estimar `k` basada en la inercia.\n",
    "   - **Coeficiente de Silueta**: La m√©trica estrella. Un valor alto (cercano a 1) es bueno. Mide cohesi√≥n y separaci√≥n para cada punto.\n",
    "   - **√çndice de Davies-Bouldin**: Un valor bajo (cercano a 0) es bueno.\n",
    "   - **√çndice de Calinski-Harabasz**: Un valor alto es bueno.\n",
    "\n",
    "3. **La Estrategia Correcta**\n",
    "   - No te f√≠es de una sola m√©trica. √ösalas en conjunto para tomar una decisi√≥n informada.\n",
    "   - Recuerda que estas m√©tricas son una gu√≠a. La validaci√≥n final a menudo requiere conocimiento del dominio y an√°lisis cualitativo.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Pr√≥ximo M√≥dulo: Algoritmos de Clustering\n",
    "\n",
    "Ya sabes qu√© es el clustering y c√≥mo evaluar sus resultados. Es hora de sumergirse en los algoritmos que hacen la magia.\n",
    "\n",
    "En el pr√≥ximo m√≥dulo, exploraremos en detalle:\n",
    "\n",
    "- **K-Means**: El algoritmo de clustering m√°s famoso y utilizado.\n",
    "- **Clustering Jer√°rquico**: Un enfoque que crea una jerarqu√≠a de cl√∫steres.\n",
    "- **DBSCAN**: Un algoritmo basado en densidad, capaz de encontrar cl√∫steres de formas arbitrarias y manejar el ruido.\n",
    "\n",
    "**Has aprendido a definir el objetivo (clustering) y a medir el √©xito (m√©tricas). Ahora, ¬°vamos a aprender a construir los motores que lo hacen posible!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
