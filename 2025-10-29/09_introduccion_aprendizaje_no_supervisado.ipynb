{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d0a6ce",
   "metadata": {},
   "source": [
    "# üåç M√≥dulo 3.1: Introducci√≥n al Aprendizaje No Supervisado\n",
    "### Curso: **Machine Learning con Python** (IFCD093PO)\n",
    "**Duraci√≥n estimada:** 4 horas\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos del M√≥dulo\n",
    "\n",
    "Bienvenido a un nuevo paradigma del Machine Learning. Hasta ahora, siempre hemos tenido una \"respuesta correcta\" (etiqueta) que gu√≠aba el aprendizaje. ¬øPero qu√© pasa cuando no la tenemos? En este m√≥dulo, te sumergir√°s en el **Aprendizaje No Supervisado**, el arte de encontrar patrones y estructura en datos sin etiquetar.\n",
    "\n",
    "Al finalizar, ser√°s capaz de:\n",
    "\n",
    "- ‚úÖ Diferenciar claramente entre **Aprendizaje Supervisado y No Supervisado**.\n",
    "- ‚úÖ Entender el prop√≥sito y las aplicaciones de las tres tareas principales del aprendizaje no supervisado:\n",
    "  - **Clustering (Agrupamiento)**: Para descubrir grupos naturales en los datos.\n",
    "  - **Reducci√≥n de Dimensionalidad**: Para simplificar y visualizar datos complejos.\n",
    "  - **Detecci√≥n de Anomal√≠as**: Para encontrar observaciones inusuales.\n",
    "- ‚úÖ Conocer los desaf√≠os √∫nicos de este tipo de aprendizaje, como la dificultad de evaluar los resultados.\n",
    "- ‚úÖ Identificar problemas de negocio que pueden resolverse con t√©cnicas no supervisadas.\n",
    "\n",
    "**¬°Prep√°rate para convertirte en un detective de datos y descubrir las historias ocultas que tus datos tienen que contar!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1584d89a",
   "metadata": {},
   "source": [
    "## üìö Tabla de Contenidos\n",
    "\n",
    "1. [Un Mundo sin Etiquetas](#1-sin-etiquetas)\n",
    "   - [Repaso: Aprendizaje Supervisado](#1.1-repaso-sup)\n",
    "   - [El Cambio de Paradigma: Aprendizaje No Supervisado](#1.2-cambio-paradigma)\n",
    "2. [Principales Tareas del Aprendizaje No Supervisado](#2-tareas)\n",
    "   - [Clustering: Encontrando los Grupos](#2.1-clustering)\n",
    "   - [Reducci√≥n de Dimensionalidad: Simplificando la Complejidad](#2.2-reduccion)\n",
    "   - [Detecci√≥n de Anomal√≠as: Buscando lo Extra√±o](#2.3-anomalias)\n",
    "3. [Aplicaciones en el Mundo Real](#3-aplicaciones)\n",
    "4. [Desaf√≠os del Aprendizaje No Supervisado](#4-desafios)\n",
    "5. [Resumen y Pr√≥ximos Pasos](#5-resumen)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942096a5",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è 1. Un Mundo sin Etiquetas <a id='1-sin-etiquetas'></a>\n",
    "\n",
    "### 1.1 Repaso: Aprendizaje Supervisado <a id='1.1-repaso-sup'></a>\n",
    "\n",
    "En el aprendizaje supervisado, el objetivo es aprender una funci√≥n que mapea las entradas `X` a las salidas `y`.\n",
    "\n",
    "`(X, y) -> Modelo -> Predicci√≥n`\n",
    "\n",
    "- **Datos**: Tenemos caracter√≠sticas (`X`) y una etiqueta o variable objetivo (`y`).\n",
    "- **Objetivo**: Predecir `y` para nuevos datos `X`.\n",
    "- **Evaluaci√≥n**: Comparamos las predicciones con las etiquetas reales (`y_test`).\n",
    "- **Ejemplos**: Predecir el precio de una casa, clasificar si un email es spam.\n",
    "\n",
    "![Supervised Learning](imagenes/Supervised_Learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fcd3d",
   "metadata": {},
   "source": [
    "### 1.2 El Cambio de Paradigma: Aprendizaje No Supervisado <a id='1.2-cambio-paradigma'></a>\n",
    "\n",
    "En el aprendizaje no supervisado, **no tenemos una variable objetivo `y`**. Solo tenemos los datos de entrada `X`.\n",
    "\n",
    "`X -> Modelo -> Estructura/Patrones`\n",
    "\n",
    "- **Datos**: Solo tenemos caracter√≠sticas (`X`). No hay \"respuesta correcta\".\n",
    "- **Objetivo**: Encontrar estructura, patrones, grupos o anomal√≠as inherentes en los datos.\n",
    "- **Evaluaci√≥n**: Mucho m√°s dif√≠cil y subjetiva. A menudo requiere inspecci√≥n humana o m√©tricas indirectas.\n",
    "- **Ejemplos**: Segmentar clientes en grupos de marketing, comprimir im√°genes, detectar transacciones fraudulentas.\n",
    "\n",
    "![Unsupervised Learning](imagenes/Unsupervised_Learning.png)\n",
    "\n",
    "**¬øPor qu√© es √∫til?** En muchos escenarios del mundo real, obtener datos etiquetados es caro, lento o simplemente imposible. El aprendizaje no supervisado nos permite extraer valor de grandes cantidades de datos sin etiquetar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8693d99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ac5fe",
   "metadata": {},
   "source": [
    "## üöÄ 2. Principales Tareas del Aprendizaje No Supervisado <a id='2-tareas'></a>\n",
    "\n",
    "Vamos a explorar las tres familias principales de algoritmos no supervisados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db91e0",
   "metadata": {},
   "source": [
    "### 2.1 Clustering: Encontrando los Grupos <a id='2.1-clustering'></a>\n",
    "\n",
    "El **clustering** es la tarea de agrupar un conjunto de objetos de tal manera que los objetos en el mismo grupo (llamado **cl√∫ster**) sean m√°s similares entre s√≠ que con los de otros grupos.\n",
    "\n",
    "**Objetivo**: Descubrir las agrupaciones naturales en los datos.\n",
    "\n",
    "**Algoritmos Comunes**: K-Means, DBSCAN, Clustering Jer√°rquico.\n",
    "\n",
    "**Ejemplo Visual**: Imagina que tenemos datos de clientes basados en sus gastos y frecuencia de compra. Un algoritmo de clustering podr√≠a identificar autom√°ticamente diferentes segmentos de clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339de42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar datos sint√©ticos con 3 grupos claros\n",
    "# make_blobs crea datos para clustering\n",
    "# Par√°metros:\n",
    "# - n_samples: n√∫mero de muestras\n",
    "# - centers: n√∫mero de centros (grupos)\n",
    "# - n_features: n√∫mero de caracter√≠sticas\n",
    "# - random_state: semilla para reproducibilidad\n",
    "# - cluster_std: desviaci√≥n est√°ndar de los clusters\n",
    "\n",
    "X, y = make_blobs(n_samples=300, centers=3, n_features=2, random_state=42, cluster_std=1.0)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50)\n",
    "plt.title(\"Datos sin Etiquetar para Clustering\")\n",
    "plt.xlabel(\"Caracter√≠stica 1\")\n",
    "plt.ylabel(\"Caracter√≠stica 2\")\n",
    "plt.show()\n",
    "\n",
    "print(\"El objetivo del clustering ser√≠a identificar estos 3 grupos sin conocer las etiquetas de color.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb45b6",
   "metadata": {},
   "source": [
    "### 2.2 Reducci√≥n de Dimensionalidad: Simplificando la Complejidad <a id='2.2-reduccion'></a>\n",
    "\n",
    "La **reducci√≥n de dimensionalidad** consiste en reducir el n√∫mero de caracter√≠sticas (dimensiones) de un conjunto de datos, conservando la mayor cantidad de informaci√≥n relevante posible.\n",
    "\n",
    "**¬øPor qu√© hacerlo?**\n",
    "- **Visualizaci√≥n**: Los humanos no podemos visualizar datos en m√°s de 3 dimensiones. Reducir los datos a 2D o 3D nos permite explorarlos visualmente.\n",
    "- **Eficiencia Computacional**: Menos caracter√≠sticas significa que los modelos se entrenan m√°s r√°pido.\n",
    "- **Combatir la \"Maldici√≥n de la Dimensionalidad\"**: En dimensiones muy altas, los datos se vuelven muy dispersos, lo que puede dificultar el aprendizaje de los modelos.\n",
    "\n",
    "**Algoritmos Comunes**: PCA (An√°lisis de Componentes Principales), t-SNE, UMAP.\n",
    "\n",
    "**Ejemplo**: El famoso dataset de d√≠gitos escritos a mano tiene 64 caracter√≠sticas (una por cada p√≠xel de 8x8). Usando PCA, podemos reducirlo a 2 caracter√≠sticas y visualizar c√≥mo se agrupan los diferentes d√≠gitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e884071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El conjunto de datos de d√≠gitos manuscritos es un buen ejemplo para aplicar PCA\n",
    "\n",
    "from sklearn.datasets import load_digits # Cargar el conjunto de datos de d√≠gitos\n",
    "from sklearn.decomposition import PCA # An√°lisis de Componentes Principales\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Ignorar advertencias para una salida m√°s limpia\n",
    "\n",
    "digits = load_digits() # Cargar datos de d√≠gitos manuscritos\n",
    "X_digits = digits.data # Datos de caracter√≠sticas (64 dimensiones)\n",
    "y_digits = digits.target # Etiquetas de los d√≠gitos (0-9)\n",
    "# Para visualizar un d√≠gito los diez primeros digitos manuscritos\n",
    "# En tama√±o m√°s peque√±o para que se vea mejor y en horizontal uno al lado del otro   \n",
    "plt.figure(figsize=(8, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(X_digits[i].reshape(8, 8), cmap='gray')\n",
    "    plt.title(f\"{y_digits[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dimensiones originales de los datos: {X_digits.shape}\")\n",
    "\n",
    "# Reducir de 64 a 2 dimensiones\n",
    "pca = PCA(n_components=2) # Inicializar PCA para 2 componentes\n",
    "X_digits_pca = pca.fit_transform(X_digits) # Aplicar PCA a los datos\n",
    "\n",
    "print(f\"Dimensiones despu√©s de PCA: {X_digits_pca.shape}\")\n",
    "\n",
    "# Visualizar los datos reducidos\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_digits_pca[:, 0], X_digits_pca[:, 1], c=y_digits, cmap=plt.cm.get_cmap('jet', 10))\n",
    "plt.colorbar(label='D√≠gito', ticks=range(10))\n",
    "plt.title(\"Visualizaci√≥n de los D√≠gitos en 2D usando PCA\")\n",
    "plt.xlabel(\"Componente Principal 1\")\n",
    "plt.ylabel(\"Componente Principal 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86731b03",
   "metadata": {},
   "source": [
    "**Explicaci√≥n del gr√°fico:**\n",
    "\n",
    "- El gr√°fico muestra c√≥mo se ven los datos de los d√≠gitos manuscritos (im√°genes de 8x8 p√≠xeles) despu√©s de aplicar **PCA** para reducir su complejidad.\n",
    "- **Originalmente**, cada imagen es un punto en un espacio de 64 dimensiones (una dimensi√≥n por cada p√≠xel).\n",
    "- **PCA** (An√°lisis de Componentes Principales) nos permite resumir la informaci√≥n m√°s importante de esos 64 valores en solo **2 dimensiones**. As√≠, podemos visualizar los datos en un plano 2D.\n",
    "- **Cada punto** en el gr√°fico es una imagen de un d√≠gito. El **color** del punto indica qu√© n√∫mero representa (del 0 al 9).\n",
    "- Si ves que los puntos del mismo color tienden a agruparse y est√°n separados de otros colores, significa que PCA ha logrado encontrar patrones que distinguen bien los diferentes d√≠gitos.\n",
    "- En resumen: este gr√°fico nos ayuda a ver si los d√≠gitos escritos a mano tienen caracter√≠sticas que los hacen distinguibles, incluso despu√©s de simplificar mucho la informaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0134d52",
   "metadata": {},
   "source": [
    "### 2.3 Detecci√≥n de Anomal√≠as: Buscando lo Extra√±o <a id='2.3-anomalias'></a>\n",
    "\n",
    "La **detecci√≥n de anomal√≠as (o outliers)** es la tarea de identificar observaciones que son raras y se desv√≠an significativamente del resto de los datos.\n",
    "\n",
    "**Objetivo**: Encontrar los \"puntos raros\".\n",
    "\n",
    "**Algoritmos Comunes**: Isolation Forest, Local Outlier Factor (LOF), One-Class SVM.\n",
    "\n",
    "**Ejemplo**: En un conjunto de datos de transacciones con tarjeta de cr√©dito, la gran mayor√≠a son leg√≠timas. Las transacciones fraudulentas son raras y tienen patrones diferentes. Un algoritmo de detecci√≥n de anomal√≠as puede identificarlas sin haber visto nunca una etiqueta de \"fraude\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b9b9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5355dc9",
   "metadata": {},
   "source": [
    "## üè¢ 3. Aplicaciones en el Mundo Real <a id='3-aplicaciones'></a>\n",
    "\n",
    "| Tarea | Aplicaci√≥n de Negocio |\n",
    "| :--- | :--- |\n",
    "| **Clustering** | **Segmentaci√≥n de Clientes**: Agrupar clientes con comportamientos de compra similares para campa√±as de marketing dirigidas. |\n",
    "| | **Agrupaci√≥n de Documentos**: Organizar noticias o documentos por temas sin necesidad de leerlos. |\n",
    "| | **Gen√≥mica**: Agrupar genes con patrones de expresi√≥n similares. |\n",
    "| **Reducci√≥n de Dim.** | **Compresi√≥n de Im√°genes**: Reducir el tama√±o de las im√°genes eliminando informaci√≥n redundante. |\n",
    "| | **Visualizaci√≥n de Datos**: Explorar datasets de alta dimensi√≥n en gr√°ficos 2D/3D. |\n",
    "| | **Preprocesamiento**: Usar las componentes principales como caracter√≠sticas para un modelo supervisado posterior. |\n",
    "| **Detecci√≥n de Anom.** | **Detecci√≥n de Fraude**: Identificar transacciones fraudulentas en sistemas bancarios. |\n",
    "| | **Mantenimiento Predictivo**: Detectar lecturas an√≥malas en sensores de maquinaria para predecir fallos. |\n",
    "| | **Ciberseguridad**: Detectar intrusiones o comportamientos extra√±os en una red. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66374398",
   "metadata": {},
   "source": [
    "## üöß 4. Desaf√≠os del Aprendizaje No Supervisado <a id='4-desafios'></a>\n",
    "\n",
    "1.  **Evaluaci√≥n Dif√≠cil**: Sin una \"verdad fundamental\" (ground truth), es dif√≠cil saber si tu modelo es \"bueno\". ¬øSon 3 cl√∫steres mejores que 4? La respuesta a menudo depende del contexto y de la interpretaci√≥n humana.\n",
    "\n",
    "2.  **Interpretaci√≥n de Resultados**: El modelo puede encontrar grupos, pero no te dice *qu√© significan*. El cient√≠fico de datos debe analizar los cl√∫steres para entender sus caracter√≠sticas y darles un nombre o sentido de negocio.\n",
    "\n",
    "3.  **Sensibilidad a los Hiperpar√°metros**: Muchos algoritmos no supervisados son muy sensibles a la configuraci√≥n de sus hiperpar√°metros (por ejemplo, el n√∫mero de cl√∫steres `k` en K-Means).\n",
    "\n",
    "4.  **La Maldici√≥n de la Dimensionalidad**: A medida que aumenta el n√∫mero de caracter√≠sticas, la distancia entre los puntos se vuelve menos significativa, lo que puede dificultar la tarea de algoritmos basados en distancia como el clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c0a72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf157ee",
   "metadata": {},
   "source": [
    "## üìù 5. Resumen y Pr√≥ximos Pasos <a id='5-resumen'></a>\n",
    "\n",
    "### üéâ ¬°Has abierto la puerta a un nuevo universo de posibilidades en Machine Learning!\n",
    "\n",
    "#### ‚úÖ Lo que has aprendido:\n",
    "\n",
    "1. **El Concepto Clave**\n",
    "   - El Aprendizaje No Supervisado se trata de **encontrar estructura en datos sin etiquetar**.\n",
    "\n",
    "2. **Las Tres Grandes Tareas**\n",
    "   - **Clustering**: Para encontrar grupos (ej. segmentos de clientes).\n",
    "   - **Reducci√≥n de Dimensionalidad**: Para simplificar y visualizar (ej. PCA).\n",
    "   - **Detecci√≥n de Anomal√≠as**: Para encontrar lo inusual (ej. fraude).\n",
    "\n",
    "3. **Aplicaciones y Desaf√≠os**\n",
    "   - Has visto c√≥mo estas t√©cnicas resuelven problemas de negocio reales.\n",
    "   - Comprendes que la evaluaci√≥n e interpretaci√≥n son los mayores desaf√≠os en este campo.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Pr√≥ximo M√≥dulo: M√©tricas en Aprendizaje No Supervisado\n",
    "\n",
    "Hemos dicho que evaluar los modelos no supervisados es dif√≠cil, pero no imposible. Existen m√©tricas que nos pueden ayudar a cuantificar la calidad de nuestros resultados, especialmente en el clustering.\n",
    "\n",
    "En el pr√≥ximo m√≥dulo, exploraremos:\n",
    "\n",
    "- **M√©tricas de Evaluaci√≥n de Clustering**: ¬øC√≥mo sabemos si nuestros cl√∫steres son buenos? Aprender√°s sobre el Coeficiente de Silueta, el √çndice de Davies-Bouldin y m√°s.\n",
    "- **El M√©todo del Codo (Elbow Method)**: Una t√©cnica para ayudarnos a elegir el n√∫mero √≥ptimo de cl√∫steres.\n",
    "\n",
    "**Has aprendido a buscar patrones. Ahora, ¬°vamos a aprender a medir la calidad de los patrones que encontramos!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
