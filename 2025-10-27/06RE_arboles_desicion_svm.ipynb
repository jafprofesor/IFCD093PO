{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd2710e",
   "metadata": {},
   "source": [
    "üìä Ejercicios Pr√°cticos: √Årboles de Decisi√≥n y SVM\n",
    "Aplicaci√≥n en Datasets Reales - California Housing, Diabetes y Titanic\n",
    "\n",
    "## Introducci√≥n General\n",
    "\n",
    "Este notebook est√° dise√±ado para que aprendas de manera pr√°ctica c√≥mo aplicar **√Årboles de Decisi√≥n** y **M√°quinas de Soporte Vectorial (SVM)** en problemas reales de Machine Learning. Usaremos tres datasets famosos: California Housing (para regresi√≥n), Diabetes (para clasificaci√≥n) y Titanic (para clasificaci√≥n con feature engineering).\n",
    "\n",
    "**¬øPor qu√© estos modelos?**\n",
    "\n",
    "- **√Årboles de Decisi√≥n**: Son f√°ciles de interpretar, no requieren escalado de datos y manejan tanto variables num√©ricas como categ√≥ricas. Son ideales para principiantes porque puedes visualizar las decisiones como un √°rbol.\n",
    "- **SVM**: Son potentes para datos complejos y robustos a outliers, pero requieren escalado y son m√°s dif√≠ciles de interpretar. Son √∫tiles cuando la precisi√≥n es clave.\n",
    "\n",
    "**¬øPor qu√© estos datasets?**\n",
    "\n",
    "- **California Housing**: Problema de regresi√≥n para predecir precios de casas. Te ayudar√° a entender c√≥mo los modelos predicen valores continuos.\n",
    "- **Diabetes**: Problema de clasificaci√≥n para predecir si la diabetes est√° avanzada. Es un dataset num√©rico limpio, perfecto para comparar modelos.\n",
    "- **Titanic**: Problema de clasificaci√≥n para predecir supervivencia. Incluye feature engineering, lo que te ense√±a a preparar datos reales con valores faltantes y variables categ√≥ricas.\n",
    "\n",
    "**Estructura del Notebook:**\n",
    "\n",
    "1. Configuraci√≥n inicial: Importar librer√≠as necesarias.\n",
    "2. Ejercicio 1: California Housing (Regresi√≥n).\n",
    "3. Ejercicio 2: Diabetes (Clasificaci√≥n).\n",
    "4. Ejercicio 3: Titanic (Clasificaci√≥n con preprocesamiento avanzado).\n",
    "5. Comparaciones y conclusiones.\n",
    "\n",
    "**Consejos para Aprender:**\n",
    "\n",
    "- Lee las explicaciones antes de ejecutar el c√≥digo.\n",
    "- Experimenta cambiando par√°metros y observa c√≥mo cambian los resultados.\n",
    "- Preg√∫ntate: ¬øPor qu√© se hace esto? ¬øQu√© pasa si no lo hago?\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Configuraci√≥n Inicial\n",
    "\n",
    "Antes de empezar, necesitamos importar todas las librer√≠as que usaremos. Esto es como preparar tus herramientas antes de construir algo.\n",
    "\n",
    "**Explicaci√≥n de las librer√≠as:**\n",
    "\n",
    "- `numpy` y `pandas`: Para manejar datos num√©ricos y tablas (DataFrames).\n",
    "- `matplotlib` y `seaborn`: Para crear gr√°ficos y visualizaciones.\n",
    "- `sklearn`: La librer√≠a principal para Machine Learning. Incluye modelos como DecisionTree y SVM, herramientas para dividir datos (train_test_split), optimizar par√°metros (GridSearchCV) y calcular m√©tricas.\n",
    "- `warnings`: Para ignorar advertencias que no son cr√≠ticas, manteniendo el output limpio.\n",
    "\n",
    "**¬øPor qu√© usar estas librer√≠as?** Scikit-learn (sklearn) es est√°ndar en ML porque es f√°cil de usar y tiene implementaciones eficientes de algoritmos. Seaborn hace gr√°ficos bonitos y f√°ciles de leer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10949582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n inicial\n",
    "\n",
    "# Importamos librer√≠as esenciales para datos y visualizaci√≥n\n",
    "import numpy as np  # Para operaciones num√©ricas r√°pidas\n",
    "import pandas as pd  # Para manejar datos en forma de tablas (DataFrames)\n",
    "import matplotlib.pyplot as plt  # Para crear gr√°ficos b√°sicos\n",
    "import seaborn as sns  # Para gr√°ficos m√°s avanzados y atractivos\n",
    "\n",
    "# Importamos herramientas de scikit-learn para Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score  # Para dividir datos y optimizar modelos\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree  # Modelos de √Årboles de Decisi√≥n\n",
    "from sklearn.svm import SVC, SVR  # Modelos de SVM para clasificaci√≥n (SVC) y regresi√≥n (SVR)\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
    "                             mean_squared_error, r2_score, precision_score, recall_score, f1_score)  # M√©tricas para evaluar modelos\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # Para escalar datos y codificar categor√≠as\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes  # Datasets de ejemplo incluidos en sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier  # Otro modelo de ensemble (no usado aqu√≠, pero disponible)\n",
    "\n",
    "# Configuramos el entorno para evitar advertencias innecesarias\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Ignoramos warnings para mantener el output limpio (en producci√≥n, revisa estos warnings)\n",
    "\n",
    "# Configuramos el estilo de los gr√°ficos para que sean m√°s atractivos\n",
    "plt.style.use('seaborn-v0_8')  # Estilo de seaborn para gr√°ficos\n",
    "sns.set_palette(\"husl\")  # Paleta de colores variada y legible\n",
    "\n",
    "# Mensaje de confirmaci√≥n para saber que todo se carg√≥ bien\n",
    "print(\"‚úÖ Librer√≠as cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06598857",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- Cada `import` trae funciones espec√≠ficas. Por ejemplo, `DecisionTreeRegressor` es para predecir n√∫meros (regresi√≥n), mientras que `DecisionTreeClassifier` es para categor√≠as (clasificaci√≥n).\n",
    "- `warnings.filterwarnings('ignore')`: En un entorno de aprendizaje, ignoramos warnings para no distraernos, pero en el mundo real, siempre rev√≠salos porque pueden indicar problemas.\n",
    "- `plt.style.use` y `sns.set_palette`: Hacen que los gr√°ficos se vean profesionales. ¬øPor qu√©? Porque las visualizaciones ayudan a entender los datos y resultados.\n",
    "\n",
    "**¬øQu√© sigue?** Ahora vamos al primer ejercicio: California Housing, donde aplicaremos estos modelos para predecir precios de casas.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Ejercicio 1: California Housing - Predicci√≥n de Precios\n",
    "\n",
    "Este ejercicio se centra en un problema de **regresi√≥n**: predecir el precio de las casas en California basado en caracter√≠sticas como ingresos medios, edad de las casas, etc. Usaremos el dataset incluido en scikit-learn.\n",
    "\n",
    "**¬øPor qu√© este dataset?** Es un problema real de regresi√≥n, ideal para aprender c√≥mo los modelos predicen valores continuos. Te ayudar√° a entender m√©tricas como RMSE (error promedio) y R¬≤ (qu√© tan bien el modelo explica los datos).\n",
    "\n",
    "**Pasos generales:**\n",
    "\n",
    "1. Cargar y explorar los datos.\n",
    "2. Visualizar relaciones.\n",
    "3. Preprocesar (dividir y escalar).\n",
    "4. Entrenar modelos (√Årbol y SVM).\n",
    "5. Evaluar y comparar.\n",
    "\n",
    "### 2.1 Carga y Exploraci√≥n de Datos\n",
    "\n",
    "Primero, cargamos el dataset y lo exploramos para entender su estructura. Esto es crucial porque nos da insights sobre qu√© variables son importantes.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- `fetch_california_housing()`: Carga el dataset directamente de sklearn. Incluye datos de casas en California con 8 caracter√≠sticas y el precio como objetivo.\n",
    "- Convertimos el precio a d√≥lares multiplicando por 100,000 (el dataset original est√° en cientos de miles).\n",
    "- Usamos `print` para mostrar informaci√≥n: forma (filas y columnas), nombres de columnas, rango de precios, primeras filas y estad√≠sticas descriptivas (media, mediana, etc.).\n",
    "- **¬øPor qu√© explorar?** Para detectar outliers, distribuciones sesgadas o correlaciones. Por ejemplo, si una variable tiene muchos valores faltantes, tendr√≠amos que manejarlo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914528dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset California Housing\n",
    "\n",
    "print(\"üè† EJERCICIO 1: CALIFORNIA HOUSING - PREDICCI√ìN DE PRECIOS\")\n",
    "\n",
    "# Cargar el dataset desde sklearn (incluye datos reales de casas en California)\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Convertir a DataFrame de pandas para manipulaci√≥n f√°cil\n",
    "df_california = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "\n",
    "# A√±adir la columna objetivo (precio) y convertir a d√≥lares para mayor claridad\n",
    "df_california['Price'] = california.target * 100000  # El target original est√° en cientos de miles, lo convertimos a d√≥lares\n",
    "\n",
    "# Mostrar informaci√≥n b√°sica del dataset\n",
    "print(\"üìä INFORMACI√ìN DEL DATASET:\")\n",
    "print(f\"Forma del dataset: {df_california.shape}\")  # N√∫mero de filas y columnas\n",
    "print(f\"Caracter√≠sticas: {list(df_california.columns)}\")  # Nombres de las columnas\n",
    "print(f\"Rango de precios: ${df_california['Price'].min():,.0f} - ${df_california['Price'].max():,.0f}\")  # Precio m√≠nimo y m√°ximo\n",
    "\n",
    "# Mostrar las primeras 5 filas para ver ejemplos de datos\n",
    "print(\"\\nüîç PRIMERAS 5 FILAS:\")\n",
    "print(df_california.head())\n",
    "\n",
    "# An√°lisis estad√≠stico: media, mediana, std, etc., para cada columna\n",
    "print(\"\\nüìà ESTAD√çSTICAS DESCRIPTIVAS:\")\n",
    "print(df_california.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afae52",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `fetch_california_housing()`: Proporciona datos limpios y listos para usar. ¬øPor qu√© usarlo? Es est√°ndar y no requiere descarga externa.\n",
    "- `df_california.describe()`: Muestra estad√≠sticas como media y desviaci√≥n est√°ndar. **¬øPor qu√©?** Para ver si hay valores extremos (outliers) que podr√≠an afectar el modelo.\n",
    "- **Consejo:** Observa el rango de precios. Si es muy amplio, el modelo podr√≠a tener dificultades; eso es normal en regresi√≥n.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Caracter√≠sticas como 'MedInc' (ingreso medio) probablemente correlacionen con el precio. Las estad√≠sticas nos dir√°n si necesitamos normalizar o manejar outliers.\n",
    "\n",
    "### 2.2 An√°lisis Exploratorio\n",
    "\n",
    "Ahora, visualizamos las relaciones entre las caracter√≠sticas y el precio para entender patrones. Esto nos ayuda a ver si hay correlaciones lineales o no lineales, y a identificar outliers.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- Usamos scatter plots para ver c√≥mo cada caracter√≠stica se relaciona con el precio. `alpha=0.3` hace los puntos semi-transparentes para ver densidades.\n",
    "- La matriz de correlaci√≥n muestra coeficientes entre -1 y 1. Valores cercanos a 1 indican correlaci√≥n positiva fuerte (e.g., m√°s ingresos = precios m√°s altos).\n",
    "- **¬øPor qu√© visualizar?** Los gr√°ficos revelan insights que las estad√≠sticas no muestran, como relaciones no lineales o clusters de datos.\n",
    "- **¬øPor qu√© grid y tight_layout?** Para que los gr√°ficos se vean ordenados y no se superpongan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de relaciones\n",
    "\n",
    "# Crear una figura con subplots (2 filas, 3 columnas) para 6 gr√°ficos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Lista de caracter√≠sticas a analizar\n",
    "caracteristicas = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n",
    "\n",
    "# Bucle para crear scatter plots para cada caracter√≠stica vs precio\n",
    "for i, feature in enumerate(caracteristicas):\n",
    "    ax = axes[i//3, i%3]  # Seleccionar el subplot correcto\n",
    "    ax.scatter(df_california[feature], df_california['Price'], alpha=0.3)  # Scatter plot con transparencia\n",
    "    ax.set_xlabel(feature)  # Etiqueta del eje X\n",
    "    ax.set_ylabel('Precio ($)')  # Etiqueta del eje Y\n",
    "    ax.set_title(f'{feature} vs Precio')  # T√≠tulo del gr√°fico\n",
    "    ax.grid(True, alpha=0.3)  # A√±adir grid para mejor lectura\n",
    "\n",
    "# Ajustar el layout para que no se superpongan los gr√°ficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de correlaci√≥n para ver relaciones entre todas las variables\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df_california.corr()  # Calcular matriz de correlaci√≥n\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')  # Heatmap con anotaciones\n",
    "plt.title('Matriz de Correlaci√≥n - California Housing')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir observaciones iniciales basadas en los gr√°ficos\n",
    "print(\"üîç OBSERVACIONES INICIALES:\")\n",
    "print(\"- MedInc (Ingreso medio) tiene alta correlaci√≥n con el precio\")\n",
    "print(\"- Algunas caracter√≠sticas tienen correlaci√≥n baja\")\n",
    "print(\"- Hay outliers en algunas variables como AveRooms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf6fdc",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `plt.subplots(2, 3)`: Crea una grid de 6 gr√°ficos. **¬øPor qu√©?** Para comparar todas las caracter√≠sticas de manera eficiente.\n",
    "- `ax.scatter`: Dibuja puntos para cada par (caracter√≠stica, precio). `alpha=0.3` evita que se vean densos.\n",
    "- `sns.heatmap`: Visualiza la matriz de correlaci√≥n. Colores rojos indican correlaci√≥n positiva, azules negativa. **¬øPor qu√©?** Para identificar r√°pidamente qu√© variables influyen en el precio.\n",
    "- **Consejo:** Busca correlaciones >0.5 o <-0.5. Si una variable no correlaciona, podr√≠a no ser √∫til para el modelo.\n",
    "\n",
    "**¬øQu√© esperamos ver?** 'MedInc' deber√≠a tener correlaci√≥n alta con 'Price'. Outliers en 'AveRooms' podr√≠an indicar datos err√≥neos o extremos (e.g., casas con muchas habitaciones).\n",
    "\n",
    "### 2.3 Preprocesamiento\n",
    "\n",
    "Antes de entrenar los modelos, necesitamos preparar los datos: separarlos en caracter√≠sticas (X) y objetivo (y), dividir en entrenamiento y prueba, y escalar para SVM.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **Separar X e y:** X son las caracter√≠sticas (inputs), y es el objetivo (precio). Usamos `drop` para eliminar 'Price' de X.\n",
    "- **Dividir datos:** Usamos `train_test_split` para crear conjuntos de entrenamiento (80%) y prueba (20%). `random_state=42` asegura reproducibilidad. **¬øPor qu√© dividir?** Para evaluar el modelo en datos no vistos y evitar overfitting.\n",
    "- **Escalar:** SVM es sensible a escalas, as√≠ que usamos `StandardScaler` para normalizar (media=0, std=1). √Årboles no lo necesitan, pero lo preparamos para ambos. **¬øPor qu√© escalar para SVM?** Variables con escalas grandes dominan el modelo; escalar las hace comparables.\n",
    "- `test_size=0.2`: 20% para prueba es est√°ndar. `stratify` no se usa aqu√≠ porque es regresi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para modelos\n",
    "\n",
    "# Separar caracter√≠sticas (X) y objetivo (y)\n",
    "X_house = df_california.drop('Price', axis=1)  # X: todas las columnas excepto 'Price'\n",
    "y_house = df_california['Price']  # y: la columna 'Price' (objetivo)\n",
    "\n",
    "# Dividir en entrenamiento y prueba (80% train, 20% test)\n",
    "X_house_train, X_house_test, y_house_train, y_house_test = train_test_split(\n",
    "    X_house, y_house, test_size=0.2, random_state=42  # random_state para reproducibilidad\n",
    ")\n",
    "\n",
    "# Escalar caracter√≠sticas (importante para SVM, no para √Årboles)\n",
    "scaler_house = StandardScaler()  # Inicializar el escalador\n",
    "X_house_train_scaled = scaler_house.fit_transform(X_house_train)  # Ajustar y transformar train\n",
    "X_house_test_scaled = scaler_house.transform(X_house_test)  # Solo transformar test (para evitar data leakage)\n",
    "\n",
    "# Confirmar que los datos est√°n listos\n",
    "print(\"‚úÖ DATOS PREPARADOS:\")\n",
    "print(f\"Entrenamiento: {X_house_train.shape[0]} muestras\")  # N√∫mero de filas en train\n",
    "print(f\"Prueba: {X_house_test.shape[0]} muestras\")  # N√∫mero de filas en test\n",
    "print(f\"Caracter√≠sticas: {X_house_train.shape[1]}\")  # N√∫mero de columnas en X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575edd6f",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `drop('Price', axis=1)`: Elimina la columna 'Price' de X. **¬øPor qu√©?** El modelo no debe ver el objetivo durante el entrenamiento.\n",
    "- `train_test_split`: Divide aleatoriamente pero reproduciblemente. **¬øPor qu√© random_state?** Para que los resultados sean consistentes al reejecutar.\n",
    "- `StandardScaler`: Transforma datos a media 0 y std 1. `fit_transform` en train aprende la media/std y transforma; `transform` en test usa los mismos valores. **¬øPor qu√© no fit en test?** Para simular datos reales no vistos.\n",
    "- **Consejo:** Siempre escala despu√©s de dividir para evitar \"data leakage\" (el modelo ve info de test).\n",
    "\n",
    "**¬øQu√© sigue?** Ahora entrenamos los modelos: primero el √Årbol de Decisi√≥n.\n",
    "\n",
    "### 2.4 Modelo: √Årbol de Decisi√≥n para Regresi√≥n\n",
    "\n",
    "Entrenamos un √Årbol de Decisi√≥n para predecir precios. Usamos GridSearchCV para encontrar los mejores par√°metros y evaluamos con m√©tricas de regresi√≥n.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **DecisionTreeRegressor:** Modelo para regresi√≥n. Divide los datos en nodos basados en caracter√≠sticas para predecir valores continuos.\n",
    "- **GridSearchCV:** Prueba combinaciones de par√°metros para encontrar el mejor modelo. **¬øPor qu√©?** Para optimizar y evitar overfitting. Usamos 'neg_mean_squared_error' porque GridSearch maximiza, pero MSE es minimizado.\n",
    "- **Par√°metros probados:** 'max_depth' limita la profundidad del √°rbol (evita overfitting); 'min_samples_split' y 'min_samples_leaf' controlan splits (evitan √°rboles demasiado complejos).\n",
    "- **M√©tricas:** RMSE (error promedio en d√≥lares), R¬≤ (proporci√≥n de varianza explicada, 1 es perfecto).\n",
    "- **Importancia de caracter√≠sticas:** Muestra qu√© variables son m√°s influyentes. **¬øPor qu√©?** Para entender el modelo y posiblemente simplificarlo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Årbol de Decisi√≥n para regresi√≥n\n",
    "\n",
    "print(\"üå≥ ENTRENANDO √ÅRBOL DE DECISI√ìN (REGRESI√ìN)\")\n",
    "\n",
    "# Definir par√°metros a probar para optimizaci√≥n\n",
    "param_grid_tree = {\n",
    "    'max_depth': [3, 5, 7, 10, 15],  # Profundidad m√°xima del √°rbol (m√°s profundo = m√°s complejo)\n",
    "    'min_samples_split': [2, 5, 10],  # M√≠nimo muestras para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4]  # M√≠nimo muestras en una hoja\n",
    "}\n",
    "\n",
    "# Inicializar el modelo base\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)  # random_state para reproducibilidad\n",
    "\n",
    "# Usar GridSearchCV para encontrar los mejores par√°metros\n",
    "grid_tree = GridSearchCV(tree_reg, param_grid_tree, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_tree.fit(X_house_train, y_house_train)  # Entrenar con datos de entrenamiento\n",
    "\n",
    "# Obtener el mejor modelo encontrado\n",
    "best_tree = grid_tree.best_estimator_\n",
    "y_pred_tree = best_tree.predict(X_house_test)  # Predecir en datos de prueba\n",
    "\n",
    "# Calcular m√©tricas de evaluaci√≥n\n",
    "mse_tree = mean_squared_error(y_house_test, y_pred_tree)  # Error cuadr√°tico medio\n",
    "rmse_tree = np.sqrt(mse_tree)  # Ra√≠z del MSE (en d√≥lares)\n",
    "r2_tree = r2_score(y_house_test, y_pred_tree)  # Coeficiente de determinaci√≥n\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"‚úÖ MEJORES PAR√ÅMETROS: {grid_tree.best_params_}\")\n",
    "print(f\"üìä RESULTADOS √ÅRBOL:\")\n",
    "print(f\" RMSE: ${rmse_tree:,.0f}\")  # Error promedio en d√≥lares\n",
    "print(f\" R¬≤: {r2_tree:.3f}\")  # Proporci√≥n de varianza explicada\n",
    "\n",
    "# Visualizar importancia de caracter√≠sticas\n",
    "importancia = pd.DataFrame({\n",
    "    'caracteristica': X_house.columns,  # Nombres de las caracter√≠sticas\n",
    "    'importancia': best_tree.feature_importances_  # Importancia calculada por el modelo\n",
    "}).sort_values('importancia', ascending=False)  # Ordenar de mayor a menor\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importancia['caracteristica'], importancia['importancia'])  # Gr√°fico de barras horizontal\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Importancia de Caracter√≠sticas - √Årbol de Decisi√≥n')\n",
    "plt.gca().invert_yaxis()  # Invertir eje Y para que la m√°s importante est√© arriba\n",
    "plt.grid(True, alpha=0.3, axis='x')  # Grid para mejor lectura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf8a2b",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `GridSearchCV:** Prueba todas las combinaciones de par√°metros (e.g., 5x3x3=45 modelos). cv=5 usa validaci√≥n cruzada. **¬øPor qu√© cv=5?\\*\\* Para una evaluaci√≥n robusta sin usar datos de prueba.\n",
    "- `best_tree.predict:** Usa el modelo optimizado para predecir. **¬øPor qu√© no usar train para predecir?\\*\\* Para evaluar generalizaci√≥n.\n",
    "- `mean_squared_error` y `r2_score:\\*\\* M√©tricas est√°ndar para regresi√≥n. RMSE es interpretable (en unidades del objetivo); R¬≤ indica qu√© tan bien el modelo se ajusta (0=mal, 1=perfecto).\n",
    "- `feature*importances*:** √Årboles calculan importancia basada en c√≥mo reducen el error. **¬øPor qu√© visualizar?\\*\\* Para ver si el modelo usa las variables esperadas (e.g., 'MedInc' deber√≠a ser alta).\n",
    "- **Consejo:** Si R¬≤ es bajo, el modelo no explica bien los datos; prueba m√°s par√°metros o feature engineering.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Un RMSE bajo (e.g., <50,000) y R¬≤ alto (e.g., >0.5). La importancia deber√≠a resaltar 'MedInc'.\n",
    "\n",
    "### 2.5 Modelo: SVM para Regresi√≥n\n",
    "\n",
    "Ahora entrenamos un SVM para regresi√≥n. SVM usa un kernel para mapear datos a un espacio de mayor dimensi√≥n donde son linealmente separables.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **SVR (Support Vector Regressor):** Versi√≥n de SVM para regresi√≥n. Encuentra un hiperplano que maximice el margen, pero permite errores dentro de un umbral (epsilon).\n",
    "- **GridSearchCV:** Optimiza par√°metros como C (penalizaci√≥n por errores), gamma (influencia de un punto) y kernel (forma de la funci√≥n).\n",
    "- **Par√°metros probados:** C alto penaliza errores m√°s; gamma alto hace el modelo m√°s complejo; kernel 'rbf' es no lineal, 'linear' es lineal.\n",
    "- **M√©tricas:** Mismas que el √Årbol (RMSE, R¬≤). SVM puede ser m√°s preciso pero m√°s lento.\n",
    "- **Escalado:** Usamos datos escalados porque SVM es sensible a escalas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM para regresi√≥n\n",
    "\n",
    "print(\"üéØ ENTRENANDO SVM (REGRESI√ìN)\")\n",
    "\n",
    "# Definir par√°metros a probar para optimizaci√≥n\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],  # Penalizaci√≥n por errores (m√°s alto = menos tolerancia)\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],  # Influencia de un punto (m√°s alto = m√°s complejo)\n",
    "    'kernel': ['rbf', 'linear']  # Tipo de kernel: 'rbf' para no lineal, 'linear' para lineal\n",
    "}\n",
    "\n",
    "# Inicializar el modelo SVR\n",
    "svm_reg = SVR()\n",
    "\n",
    "# Usar GridSearchCV para encontrar los mejores par√°metros\n",
    "grid_svm = GridSearchCV(svm_reg, param_grid_svm, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_svm.fit(X_house_train_scaled, y_house_train)  # Entrenar con datos escalados\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_house_test_scaled)  # Predecir en datos de prueba escalados\n",
    "\n",
    "# Calcular m√©tricas\n",
    "mse_svm = mean_squared_error(y_house_test, y_pred_svm)  # Error cuadr√°tico medio\n",
    "rmse_svm = np.sqrt(mse_svm)  # Ra√≠z del MSE\n",
    "r2_svm = r2_score(y_house_test, y_pred_svm)  # R¬≤\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"‚úÖ MEJORES PAR√ÅMETROS: {grid_svm.best_params_}\")\n",
    "print(f\"üìä RESULTADOS SVM:\")\n",
    "print(f\" RMSE: ${rmse_svm:,.0f}\")\n",
    "print(f\" R¬≤: {r2_svm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbedaa",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `param_grid_svm:\\*\\* Prueba combinaciones (e.g., 4x4x2=32 modelos). cv=3 es m√°s r√°pido que cv=5 para SVM, ya que son lentos.\n",
    "- `SVR():** Usa kernel 'rbf' por defecto. **¬øPor qu√© kernel?\\*\\* Para capturar relaciones no lineales en los datos.\n",
    "- `fit con datos escalados:** SVM requiere escalado para funcionar bien. **¬øPor qu√©?\\*\\* Variables con escalas diferentes afectan el c√°lculo del margen.\n",
    "- `predict en test escalado:\\*\\* Asegura consistencia.\n",
    "- **Consejo:** Si el modelo es lento, reduce el grid o usa cv=3. Compara RMSE y R¬≤ con el √Årbol.\n",
    "\n",
    "**¬øQu√© esperamos ver?** SVM podr√≠a tener RMSE similar o mejor que el √Årbol, pero toma m√°s tiempo. R¬≤ alto indica buen ajuste.\n",
    "\n",
    "### 2.6 Comparaci√≥n y An√°lisis\n",
    "\n",
    "Finalmente, comparamos los resultados de ambos modelos para ver cu√°l es mejor en este dataset.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **DataFrame de resultados:** Creamos una tabla con m√©tricas para comparar f√°cilmente.\n",
    "- **Gr√°ficos de barras:** Visualizamos R¬≤ (cuanto m√°s alto mejor) y RMSE (cuanto m√°s bajo mejor). Colores diferentes para distinguir modelos.\n",
    "- **Textos en barras:** A√±adimos valores exactos para precisi√≥n.\n",
    "- **Conclusiones:** Basadas en m√©tricas, determinamos el mejor modelo. **¬øPor qu√© comparar?** Para elegir el modelo m√°s adecuado para el problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c94ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de modelos\n",
    "\n",
    "print(\"üìä COMPARACI√ìN FINAL - CALIFORNIA HOUSING\")\n",
    "\n",
    "# Crear DataFrame con resultados para comparaci√≥n\n",
    "resultados_california = pd.DataFrame({\n",
    "    'Modelo': ['√Årbol de Decisi√≥n', 'SVM'],\n",
    "    'RMSE': [rmse_tree, rmse_svm],  # Error promedio en d√≥lares\n",
    "    'R¬≤': [r2_tree, r2_svm]  # Proporci√≥n de varianza explicada\n",
    "})\n",
    "\n",
    "print(resultados_california)  # Mostrar tabla de resultados\n",
    "\n",
    "# Visualizaci√≥n comparativa\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Comparaci√≥n R¬≤ (m√°s alto es mejor)\n",
    "axes[0].bar(resultados_california['Modelo'], resultados_california['R¬≤'], color=['skyblue', 'lightcoral'])\n",
    "axes[0].set_ylabel('R¬≤ Score')\n",
    "axes[0].set_title('Comparaci√≥n: R¬≤ Score')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparaci√≥n RMSE (m√°s bajo es mejor)\n",
    "axes[1].bar(resultados_california['Modelo'], resultados_california['RMSE'], color=['skyblue', 'lightcoral'])\n",
    "axes[1].set_ylabel('RMSE ($)')\n",
    "axes[1].set_title('Comparaci√≥n: Error (RMSE)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# A√±adir valores exactos en las barras\n",
    "for i, (modelo, r2, rmse) in enumerate(zip(resultados_california['Modelo'],\n",
    "                                            resultados_california['R¬≤'],\n",
    "                                            resultados_california['RMSE'])):\n",
    "    axes[0].text(i, r2 + 0.01, f'{r2:.3f}', ha='center', va='bottom')  # Texto para R¬≤\n",
    "    axes[1].text(i, rmse + 1000, f'${rmse:,.0f}', ha='center', va='bottom')  # Texto para RMSE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Conclusiones basadas en m√©tricas\n",
    "print(\"üí° CONCLUSIONES CALIFORNIA HOUSING:\")\n",
    "print(f\"‚Ä¢ Mejor modelo: {'√Årbol de Decisi√≥n' if r2_tree > r2_svm else 'SVM'}\")\n",
    "print(f\"‚Ä¢ El error promedio es de aproximadamente ${min(rmse_tree, rmse_svm):,.0f}\")\n",
    "print(f\"‚Ä¢ El modelo explica el {max(r2_tree, r2_svm)*100:.1f}% de la variaci√≥n en los precios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf418f7",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `pd.DataFrame:** Crea una tabla para comparar m√©tricas. **¬øPor qu√©?\\*\\* Facilita la lectura de resultados.\n",
    "- `plt.subplots(1, 2):** Dos gr√°ficos lado a lado. **¬øPor qu√©?\\*\\* Para comparar R¬≤ y RMSE visualmente.\n",
    "- `axes[0].bar:\\*\\* Gr√°fico de barras para R¬≤. Color 'skyblue' para √Årbol, 'lightcoral' para SVM.\n",
    "- `axes[1].bar:** Gr√°fico para RMSE. **¬øPor qu√© invertir colores?\\*\\* Para consistencia.\n",
    "- `text:** A√±ade valores en las barras. **¬øPor qu√©?\\*\\* Para ver n√∫meros exactos sin leer el DataFrame.\n",
    "- **Conclusiones:** Usa condicionales para determinar el mejor basado en R¬≤ (m√°s alto gana). **¬øPor qu√© R¬≤?** Indica qu√© tan bien el modelo explica los datos.\n",
    "\n",
    "**¬øQu√© esperamos ver?** El √Årbol podr√≠a ser mejor en interpretabilidad, SVM en precisi√≥n. El error promedio nos dice cu√°nto se equivoca el modelo en d√≥lares.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Ejercicio 2: Diabetes - Predicci√≥n de Enfermedad\n",
    "\n",
    "Este ejercicio es un problema de **clasificaci√≥n**: predecir si la diabetes est√° avanzada basado en caracter√≠sticas m√©dicas. Convertimos el dataset de regresi√≥n a binario para clasificaci√≥n.\n",
    "\n",
    "**¬øPor qu√© este dataset?** Es un dataset num√©rico limpio de sklearn, ideal para comparar modelos en clasificaci√≥n. Te ense√±a a convertir problemas de regresi√≥n a clasificaci√≥n.\n",
    "\n",
    "**Pasos generales:**\n",
    "\n",
    "1. Cargar y explorar los datos.\n",
    "2. Visualizar distribuciones por clase.\n",
    "3. Preprocesar (dividir y escalar).\n",
    "4. Entrenar modelos (√Årbol y SVM).\n",
    "5. Evaluar y comparar.\n",
    "\n",
    "### 3.1 Carga y Exploraci√≥n de Datos\n",
    "\n",
    "Cargamos el dataset Diabetes y lo convertimos a un problema binario para clasificaci√≥n.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- `load_diabetes()`: Carga datos de progresi√≥n de diabetes. Originalmente para regresi√≥n, lo convertimos a binario usando la mediana como umbral.\n",
    "- **Convertir a binario:** Valores > mediana = 1 (avanzada), <= mediana = 0 (no avanzada). **¬øPor qu√©?** Para hacer un problema de clasificaci√≥n.\n",
    "- Mostramos forma, caracter√≠sticas, distribuci√≥n de clases, primeras filas y estad√≠sticas.\n",
    "- **¬øPor qu√© explorar?** Para ver balance de clases y distribuciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857838c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset Diabetes\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü©∫ EJERCICIO 2: DIABETES - PREDICCI√ìN DE ENFERMEDAD\")\n",
    "\n",
    "# Cargar el dataset desde sklearn (datos de progresi√≥n de diabetes)\n",
    "diabetes = load_diabetes()\n",
    "df_diabetes = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "df_diabetes['target'] = diabetes.target  # A√±adir la columna objetivo (progresi√≥n de diabetes)\n",
    "\n",
    "# Para clasificaci√≥n, convertimos en problema binario\n",
    "# Valores altos de target indican mayor progresi√≥n de diabetes\n",
    "umbral = df_diabetes['target'].median()  # Usar mediana como umbral\n",
    "df_diabetes['diabetes_avanzada'] = (df_diabetes['target'] > umbral).astype(int)  # 1 si avanzada, 0 si no\n",
    "\n",
    "# Mostrar informaci√≥n del dataset\n",
    "print(\"üìä INFORMACI√ìN DEL DATASET:\")\n",
    "print(f\"Forma del dataset: {df_diabetes.shape}\")  # Filas y columnas\n",
    "print(f\"Caracter√≠sticas: {list(diabetes.feature_names)}\")  # Nombres de variables\n",
    "print(f\"Distribuci√≥n de clases:\")\n",
    "print(df_diabetes['diabetes_avanzada'].value_counts())  # Conteo de 0 y 1\n",
    "\n",
    "# Mostrar las primeras 5 filas\n",
    "print(\"\\nüîç PRIMERAS 5 FILAS:\")\n",
    "print(df_diabetes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c630329",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `load_diabetes():` Proporciona datos m√©dicos estandarizados. **¬øPor qu√© usarlo?** Es limpio y no requiere preprocesamiento inicial.\n",
    "- `umbral = df_diabetes['target'].median():` Mediana asegura balance aproximado de clases. **¬øPor qu√© mediana?** Para evitar sesgo si hay outliers.\n",
    "- `astype(int):` Convierte booleanos a enteros (0/1).\n",
    "- **Consejo:** Observa la distribuci√≥n de clases. Si est√° desbalanceada, considera t√©cnicas como oversampling.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Clases balanceadas (alrededor de 50% cada una). Caracter√≠sticas como 'bmi' (IMC) podr√≠an correlacionar con diabetes avanzada.\n",
    "\n",
    "### 3.2 An√°lisis Exploratorio\n",
    "\n",
    "Visualizamos las distribuciones de las caracter√≠sticas por clase para ver diferencias entre diabetes avanzada y no avanzada.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **Boxplots:** Muestran la distribuci√≥n de cada caracter√≠stica por clase. La caja representa el 50% central, la l√≠nea la mediana, y los bigotes los extremos.\n",
    "- **Matriz de correlaci√≥n:** Similar a antes, pero ahora incluye la nueva columna 'diabetes_avanzada'.\n",
    "- **¬øPor qu√© boxplots?** Para ver si hay diferencias en las distribuciones (e.g., BMI m√°s alto en diabetes avanzada).\n",
    "- **¬øPor qu√© grid?** Para organizar m√∫ltiples gr√°ficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ddb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis exploratorio diabetes\n",
    "\n",
    "# Crear figura con subplots para boxplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Lista de caracter√≠sticas a analizar\n",
    "caracteristicas_diabetes = ['age', 'bmi', 'bp', 's1', 's2', 's3']\n",
    "\n",
    "# Bucle para crear boxplots por clase\n",
    "for i, feature in enumerate(caracteristicas_diabetes):\n",
    "    ax = axes[i//3, i%3]  # Seleccionar subplot\n",
    "    # Datos para cada clase\n",
    "    data_to_plot = [df_diabetes[df_diabetes['diabetes_avanzada'] == 0][feature],\n",
    "                   df_diabetes[df_diabetes['diabetes_avanzada'] == 1][feature]]\n",
    "    ax.boxplot(data_to_plot, labels=['No Avanzada', 'Avanzada'])  # Boxplot con etiquetas\n",
    "    ax.set_ylabel(feature)  # Etiqueta del eje Y\n",
    "    ax.set_title(f'Distribuci√≥n de {feature} por Clase')  # T√≠tulo\n",
    "    ax.grid(True, alpha=0.3)  # Grid para mejor lectura\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de correlaci√≥n para ver relaciones\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_diabetes = df_diabetes.corr()  # Calcular correlaci√≥n\n",
    "sns.heatmap(corr_diabetes, annot=True, cmap='coolwarm', center=0, fmt='.2f')  # Heatmap\n",
    "plt.title('Matriz de Correlaci√≥n - Diabetes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6a669",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `plt.subplots(2, 3):` Crea 6 gr√°ficos. **¬øPor qu√©?** Para comparar todas las caracter√≠sticas.\n",
    "- `ax.boxplot:** Dibuja cajas para cada clase. **¬øPor qu√©?\\*\\* Para ver si hay separaci√≥n entre clases (e.g., BMI m√°s alto en avanzada).\n",
    "- `sns.heatmap:** Visualiza correlaciones. **¬øPor qu√©?\\*\\* Para ver qu√© variables correlacionan con 'diabetes_avanzada'.\n",
    "- **Consejo:** Busca diferencias en medianas o outliers entre clases. Si no hay separaci√≥n, el modelo podr√≠a tener dificultades.\n",
    "\n",
    "**¬øQu√© esperamos ver?** 'bmi' y 'bp' podr√≠an tener distribuciones diferentes por clase. Correlaciones con 'diabetes_avanzada' indican variables √∫tiles.\n",
    "\n",
    "### 3.3 Preprocesamiento\n",
    "\n",
    "Preparamos los datos para clasificaci√≥n: separamos X e y, dividimos en train/test con estratificaci√≥n, y escalamos para SVM.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **Separar X e y:** X son las caracter√≠sticas (sin 'target' ni 'diabetes_avanzada'), y es la clase binaria.\n",
    "- **Dividir datos:** 70% train, 30% test. `stratify=y_diabetes` asegura balance de clases en ambos sets. **¬øPor qu√© estratificar?** Para que train y test tengan la misma proporci√≥n de clases.\n",
    "- **Escalar:** SVM necesita escalado; √Årboles no, pero lo preparamos.\n",
    "- **¬øPor qu√© test_size=0.3?** M√°s datos para test en clasificaci√≥n para evaluar mejor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab78776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para clasificaci√≥n\n",
    "\n",
    "# Separar caracter√≠sticas (X) y objetivo (y)\n",
    "X_diabetes = df_diabetes.drop(['target', 'diabetes_avanzada'], axis=1)  # X: caracter√≠sticas originales\n",
    "y_diabetes = df_diabetes['diabetes_avanzada']  # y: clase binaria\n",
    "\n",
    "# Dividir en entrenamiento y prueba (70% train, 30% test) con estratificaci√≥n\n",
    "X_diab_train, X_diab_test, y_diab_train, y_diab_test = train_test_split(\n",
    "    X_diabetes, y_diabetes, test_size=0.3, random_state=42, stratify=y_diabetes  # stratify para balance de clases\n",
    ")\n",
    "\n",
    "# Escalar caracter√≠sticas para SVM\n",
    "scaler_diab = StandardScaler()  # Inicializar escalador\n",
    "X_diab_train_scaled = scaler_diab.fit_transform(X_diab_train)  # Ajustar y transformar train\n",
    "X_diab_test_scaled = scaler_diab.transform(X_diab_test)  # Solo transformar test\n",
    "\n",
    "# Confirmar preparaci√≥n\n",
    "print(\"‚úÖ DATOS DIABETES PREPARADOS:\")\n",
    "print(f\"Entrenamiento: {X_diab_train.shape[0]} muestras\")  # N√∫mero de filas en train\n",
    "print(f\"Prueba: {X_diab_test.shape[0]} muestras\")  # N√∫mero de filas en test\n",
    "print(f\"Proporci√≥n clases entrenamiento: {y_diab_train.value_counts(normalize=True).to_dict()}\")  # Balance de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d671e",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `drop(['target', 'diabetes_avanzada'], axis=1):` Elimina columnas no necesarias. **¬øPor qu√©?** 'target' es el original, 'diabetes_avanzada' es y.\n",
    "- `stratify=y_diabetes:` Mantiene proporci√≥n de clases. **¬øPor qu√©?** Evita que un set tenga solo una clase.\n",
    "- `StandardScaler:` Normaliza datos. **¬øPor qu√©?** SVM funciona mejor con escalas similares.\n",
    "- **Consejo:** Verifica el balance de clases. Si desbalanceado, considera t√©cnicas como SMOTE.\n",
    "\n",
    "**¬øQu√© sigue?** Entrenamos los modelos de clasificaci√≥n.\n",
    "\n",
    "### 3.4 Modelo: √Årbol de Decisi√≥n para Clasificaci√≥n\n",
    "\n",
    "Entrenamos un √Årbol de Decisi√≥n para clasificar diabetes avanzada. Usamos GridSearchCV para optimizar par√°metros y evaluamos con m√©tricas de clasificaci√≥n.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **DecisionTreeClassifier:** Modelo para clasificaci√≥n. Usa criterios como 'gini' o 'entropy' para dividir nodos.\n",
    "- **GridSearchCV:** Prueba par√°metros para maximizar exactitud. **¬øPor qu√©?** Para evitar overfitting y mejorar generalizaci√≥n.\n",
    "- **Par√°metros probados:** 'max_depth' limita complejidad; 'min_samples_split' y 'criterion' controlan splits y medida de impureza.\n",
    "- **M√©tricas:** Exactitud (porcentaje correcto), Precisi√≥n (de positivos predichos, cu√°ntos son reales), Recall (de positivos reales, cu√°ntos predice), F1-Score (balance de precisi√≥n y recall).\n",
    "- **Matriz de confusi√≥n:** Muestra verdaderos positivos, falsos positivos, etc. **¬øPor qu√©?** Para ver errores espec√≠ficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5346189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Årbol de Decisi√≥n para clasificaci√≥n\n",
    "\n",
    "print(\"üå≥ ENTRENANDO √ÅRBOL DE DECISI√ìN (CLASIFICACI√ìN)\")\n",
    "\n",
    "# Definir par√°metros a probar\n",
    "param_grid_tree_clf = {\n",
    "    'max_depth': [3, 5, 7, 10],  # Profundidad m√°xima\n",
    "    'min_samples_split': [2, 5, 10],  # M√≠nimo muestras para split\n",
    "    'criterion': ['gini', 'entropy']  # Criterio de divisi√≥n: gini (default) o entropy\n",
    "}\n",
    "\n",
    "# Inicializar modelo\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)  # random_state para reproducibilidad\n",
    "\n",
    "# Optimizar con GridSearchCV\n",
    "grid_tree_clf = GridSearchCV(tree_clf, param_grid_tree_clf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_tree_clf.fit(X_diab_train, y_diab_train)  # Entrenar\n",
    "\n",
    "# Mejor modelo y predicciones\n",
    "best_tree_clf = grid_tree_clf.best_estimator_\n",
    "y_pred_tree_clf = best_tree_clf.predict(X_diab_test)  # Predecir en test\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy_tree = accuracy_score(y_diab_test, y_pred_tree_clf)  # Exactitud\n",
    "precision_tree = precision_score(y_diab_test, y_pred_tree_clf)  # Precisi√≥n\n",
    "recall_tree = recall_score(y_diab_test, y_pred_tree_clf)  # Recall\n",
    "f1_tree = f1_score(y_diab_test, y_pred_tree_clf)  # F1-Score\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"‚úÖ MEJORES PAR√ÅMETROS: {grid_tree_clf.best_params_}\")\n",
    "print(f\"üìä RESULTADOS √ÅRBOL:\")\n",
    "print(f\" Exactitud: {accuracy_tree:.3f}\")\n",
    "print(f\" Precisi√≥n: {precision_tree:.3f}\")\n",
    "print(f\" Recall: {recall_tree:.3f}\")\n",
    "print(f\" F1-Score: {f1_tree:.3f}\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_tree = confusion_matrix(y_diab_test, y_pred_tree_clf)  # Calcular matriz\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_tree, annot=True, fmt='d', cmap='Blues',  # Heatmap con n√∫meros\n",
    "            xticklabels=['No Avanzada', 'Avanzada'],\n",
    "            yticklabels=['No Avanzada', 'Avanzada'])\n",
    "plt.title('Matriz de Confusi√≥n - √Årbol de Decisi√≥n (Diabetes)')\n",
    "plt.ylabel('Real')  # Etiqueta Y: valores reales\n",
    "plt.xlabel('Predicci√≥n')  # Etiqueta X: valores predichos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d769b",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `param_grid_tree_clf:\\*\\* Prueba combinaciones (e.g., 4x3x2=24 modelos). cv=5 para validaci√≥n robusta.\n",
    "- `DecisionTreeClassifier:** Usa 'gini' por defecto. **¬øPor qu√© criterion?\\*\\* 'gini' es m√°s r√°pido; 'entropy' es m√°s informativo.\n",
    "- `grid_tree_clf.fit:\\*\\* Entrena con datos no escalados (√Årboles no lo necesitan).\n",
    "- `predict:\\*\\* Clasifica en 0 o 1.\n",
    "- `accuracy_score, etc.:** M√©tricas para clasificaci√≥n. **¬øPor qu√© m√∫ltiples?\\*\\* Exactitud es general; precisi√≥n/recall para clases desbalanceadas.\n",
    "- `confusion_matrix:** Filas = real, columnas = predicho. **¬øPor qu√© visualizar?\\*\\* Para ver falsos positivos/negativos.\n",
    "- **Consejo:** Si recall es bajo, el modelo pierde muchos positivos reales; ajusta par√°metros.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Exactitud >0.7, matriz con m√°s aciertos en diagonal. 'bmi' podr√≠a ser importante.\n",
    "\n",
    "### 3.5 Modelo: SVM para Clasificaci√≥n\n",
    "\n",
    "Entrenamos un SVM para clasificar diabetes avanzada. SVM es efectivo para datos num√©ricos limpios como este.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **SVC (Support Vector Classifier):** Versi√≥n de SVM para clasificaci√≥n. Encuentra el hiperplano que maximice el margen entre clases.\n",
    "- **GridSearchCV:** Optimiza par√°metros para maximizar exactitud. **¬øPor qu√©?** Para encontrar el mejor modelo.\n",
    "- **Par√°metros probados:** C (penalizaci√≥n por errores), gamma (influencia), kernel (forma de la funci√≥n).\n",
    "- **M√©tricas:** Mismas que el √Årbol. SVM podr√≠a ser m√°s preciso en datos limpios.\n",
    "- **Matriz de confusi√≥n:** Similar al √Årbol, pero con colores diferentes para distinguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473de0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM para clasificaci√≥n\n",
    "\n",
    "print(\"üéØ ENTRENANDO SVM (CLASIFICACI√ìN)\")\n",
    "\n",
    "# Definir par√°metros a probar\n",
    "param_grid_svm_clf = {\n",
    "    'C': [0.1, 1, 10, 100],  # Penalizaci√≥n por errores (m√°s alto = menos tolerancia)\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],  # Influencia de un punto\n",
    "    'kernel': ['rbf', 'linear']  # Kernel: 'rbf' para no lineal, 'linear' para lineal\n",
    "}\n",
    "\n",
    "# Inicializar modelo\n",
    "svm_clf = SVC(random_state=42)  # random_state para reproducibilidad\n",
    "\n",
    "# Optimizar con GridSearchCV\n",
    "grid_svm_clf = GridSearchCV(svm_clf, param_grid_svm_clf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_svm_clf.fit(X_diab_train_scaled, y_diab_train)  # Entrenar con datos escalados\n",
    "\n",
    "# Mejor modelo y predicciones\n",
    "best_svm_clf = grid_svm_clf.best_estimator_\n",
    "y_pred_svm_clf = best_svm_clf.predict(X_diab_test_scaled)  # Predecir en test escalado\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy_svm = accuracy_score(y_diab_test, y_pred_svm_clf)  # Exactitud\n",
    "precision_svm = precision_score(y_diab_test, y_pred_svm_clf)  # Precisi√≥n\n",
    "recall_svm = recall_score(y_diab_test, y_pred_svm_clf)  # Recall\n",
    "f1_svm = f1_score(y_diab_test, y_pred_svm_clf)  # F1-Score\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"‚úÖ MEJORES PAR√ÅMETROS: {grid_svm_clf.best_params_}\")\n",
    "print(f\"üìä RESULTADOS SVM:\")\n",
    "print(f\" Exactitud: {accuracy_svm:.3f}\")\n",
    "print(f\" Precisi√≥n: {precision_svm:.3f}\")\n",
    "print(f\" Recall: {recall_svm:.3f}\")\n",
    "print(f\" F1-Score: {f1_svm:.3f}\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_svm = confusion_matrix(y_diab_test, y_pred_svm_clf)  # Calcular matriz\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Reds',  # Heatmap con colores rojos\n",
    "            xticklabels=['No Avanzada', 'Avanzada'],\n",
    "            yticklabels=['No Avanzada', 'Avanzada'])\n",
    "plt.title('Matriz de Confusi√≥n - SVM (Diabetes)')\n",
    "plt.ylabel('Real')  # Etiqueta Y: valores reales\n",
    "plt.xlabel('Predicci√≥n')  # Etiqueta X: valores predichos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cee96c",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `param_grid_svm_clf:\\*\\* Prueba combinaciones (e.g., 4x4x2=32 modelos). cv=5 para validaci√≥n.\n",
    "- `SVC:** Usa kernel 'rbf' por defecto. **¬øPor qu√© kernel?\\*\\* Para capturar relaciones no lineales.\n",
    "- `fit con datos escalados:** SVM requiere escalado. **¬øPor qu√©?\\*\\* Para calcular m√°rgenes correctamente.\n",
    "- `predict:\\*\\* Clasifica en 0 o 1.\n",
    "- `accuracy_score, etc.:\\*\\* Mismas m√©tricas que el √Årbol.\n",
    "- `confusion_matrix:\\*\\* Similar al √Årbol, pero cmap='Reds' para diferenciar.\n",
    "- **Consejo:** Compara con el √Årbol. SVM podr√≠a tener mejor exactitud en datos num√©ricos.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Exactitud similar o mejor que el √Årbol, matriz con aciertos en diagonal.\n",
    "\n",
    "### 3.6 Comparaci√≥n y An√°lisis\n",
    "\n",
    "Comparamos los modelos para Diabetes usando m√∫ltiples m√©tricas de clasificaci√≥n.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **DataFrame de resultados:** Tabla con m√©tricas para ambos modelos.\n",
    "- **Gr√°ficos de barras:** 2x2 grid para comparar Exactitud, Precisi√≥n, Recall y F1-Score. **¬øPor qu√© m√∫ltiples m√©tricas?** Para evaluar balance entre precisi√≥n y recall.\n",
    "- **Textos en barras:** Valores exactos para claridad.\n",
    "- **Conclusiones:** Basadas en exactitud, determinamos el mejor. **¬øPor qu√© exactitud?** Es la m√©trica principal para clasificaci√≥n balanceada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de modelos diabetes\n",
    "\n",
    "print(\"üìä COMPARACI√ìN FINAL - DIABETES\")\n",
    "\n",
    "# Crear DataFrame con m√©tricas\n",
    "resultados_diabetes = pd.DataFrame({\n",
    "    'Modelo': ['√Årbol de Decisi√≥n', 'SVM'],\n",
    "    'Exactitud': [accuracy_tree, accuracy_svm],  # Porcentaje de predicciones correctas\n",
    "    'Precisi√≥n': [precision_tree, precision_svm],  # De positivos predichos, cu√°ntos son reales\n",
    "    'Recall': [recall_tree, recall_svm],  # De positivos reales, cu√°ntos predice\n",
    "    'F1-Score': [f1_tree, f1_svm]  # Balance de precisi√≥n y recall\n",
    "})\n",
    "\n",
    "print(resultados_diabetes)  # Mostrar tabla\n",
    "\n",
    "# Visualizaci√≥n comparativa\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))  # 2x2 grid de gr√°ficos\n",
    "metricas = ['Exactitud', 'Precisi√≥n', 'Recall', 'F1-Score']  # M√©tricas a comparar\n",
    "\n",
    "for i, metrica in enumerate(metricas):\n",
    "    ax = axes[i//2, i%2]  # Seleccionar subplot\n",
    "    valores = resultados_diabetes[metrica]  # Valores para la m√©trica\n",
    "    bars = ax.bar(resultados_diabetes['Modelo'], valores,  # Gr√°fico de barras\n",
    "                  color=['skyblue', 'lightcoral'])\n",
    "    ax.set_ylabel(metrica)  # Etiqueta Y\n",
    "    ax.set_title(f'Comparaci√≥n: {metrica}')  # T√≠tulo\n",
    "    ax.set_ylim(0, 1)  # L√≠mite Y de 0 a 1\n",
    "    ax.grid(True, alpha=0.3)  # Grid\n",
    "\n",
    "    # A√±adir valores en las barras\n",
    "    for bar, valor in zip(bars, valores):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, valor + 0.01,\n",
    "                f'{valor:.3f}', ha='center', va='bottom')  # Texto con valor\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Conclusiones\n",
    "print(\"üí° CONCLUSIONES DIABETES:\")\n",
    "mejor_modelo_diab = '√Årbol de Decisi√≥n' if accuracy_tree > accuracy_svm else 'SVM'\n",
    "print(f\"‚Ä¢ Mejor modelo: {mejor_modelo_diab}\")\n",
    "print(f\"‚Ä¢ Exactitud del mejor modelo: {max(accuracy_tree, accuracy_svm):.3f}\")\n",
    "print(f\"‚Ä¢ El modelo puede ayudar a identificar pacientes con diabetes avanzada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437f933",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `pd.DataFrame:** Crea tabla con m√©tricas. **¬øPor qu√©?\\*\\* Para comparar f√°cilmente.\n",
    "- `plt.subplots(2, 2):** 4 gr√°ficos en grid. **¬øPor qu√©?\\*\\* Para ver todas las m√©tricas.\n",
    "- `ax.bar:\\*\\* Gr√°fico para cada m√©trica. Colores para diferenciar modelos.\n",
    "- `text:** A√±ade valores. **¬øPor qu√©?\\*\\* Para precisi√≥n sin leer tabla.\n",
    "- **Conclusiones:** Usa exactitud para decidir. **¬øPor qu√©?** Es la m√°s intuitiva para clasificaci√≥n balanceada.\n",
    "- **Consejo:** Si recall es importante (e.g., detectar diabetes), prior√≠zalo.\n",
    "\n",
    "**¬øQu√© esperamos ver?** SVM podr√≠a tener mejor exactitud en datos num√©ricos. El modelo ayuda a identificar diabetes avanzada para intervenciones tempranas.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Ejercicio 3: Titanic - Predicci√≥n de Supervivencia\n",
    "\n",
    "Este ejercicio es un problema de **clasificaci√≥n** con feature engineering: predecir supervivencia en el Titanic. Incluye manejo de valores faltantes y creaci√≥n de nuevas caracter√≠sticas.\n",
    "\n",
    "**¬øPor qu√© este dataset?** Es un dataset cl√°sico con datos mixtos (num√©ricos y categ√≥ricos), valores faltantes y necesidad de feature engineering. Te ense√±a a preparar datos reales.\n",
    "\n",
    "**Pasos generales:**\n",
    "\n",
    "1. Cargar y explorar los datos.\n",
    "2. Visualizar relaciones y crear insights.\n",
    "3. Preprocesar (manejar faltantes, feature engineering, codificar).\n",
    "4. Entrenar modelos (√Årbol y SVM).\n",
    "5. Evaluar y comparar.\n",
    "\n",
    "### 4.1 Carga y Exploraci√≥n de Datos\n",
    "\n",
    "Cargamos el dataset Titanic y exploramos su estructura, incluyendo valores faltantes.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- `sns.load_dataset('titanic'):` Carga desde seaborn. Si falla, usa URL alternativa.\n",
    "- Mostramos forma, columnas, distribuci√≥n de supervivencia, valores faltantes y primeras filas.\n",
    "- **¬øPor qu√© explorar?** Para ver desbalance de clases, variables categ√≥ricas y datos faltantes (e.g., 'age' y 'embarked').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c75d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset Titanic\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üö¢ EJERCICIO 3: TITANIC - PREDICCI√ìN DE SUPERVIVENCIA\")\n",
    "\n",
    "# Cargar datos desde seaborn (o URL si falla)\n",
    "#try:\n",
    "#    df_titanic = sns.load_dataset('titanic')  # Intentar cargar desde seaborn\n",
    "#except:  # Si no funciona, cargar desde URL\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df_titanic = pd.read_csv(url)\n",
    "\n",
    "# Mostrar informaci√≥n del dataset\n",
    "print(\"üìä INFORMACI√ìN DEL DATASET:\")\n",
    "print(f\"Forma del dataset: {df_titanic.shape}\")  # Filas y columnas\n",
    "print(f\"Columnas: {list(df_titanic.columns)}\")  # Nombres de columnas\n",
    "print(f\"\\nDistribuci√≥n de supervivencia:\")\n",
    "print(df_titanic['Survived'].value_counts())  # Conteo de 0 (no sobrevivi√≥) y 1 (sobrevivi√≥)\n",
    "print(f\"\\nValores faltantes:\")\n",
    "print(df_titanic.isnull().sum())  # N√∫mero de valores faltantes por columna\n",
    "\n",
    "# Mostrar las primeras 5 filas\n",
    "print(\"\\nüîç PRIMERAS 5 FILAS:\")\n",
    "print(df_titanic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297d475",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `try-except:` Para manejar si seaborn no est√° disponible. **¬øPor qu√©?** Para robustez.\n",
    "- `df_titanic.shape:` Muestra (filas, columnas). **¬øPor qu√©?** Para ver tama√±o del dataset.\n",
    "- `value_counts():` Conteo de clases. **¬øPor qu√©?** Para ver desbalance (e.g., m√°s no sobrevivieron).\n",
    "- `isnull().sum():` Valores faltantes. **¬øPor qu√©?** Para planificar preprocesamiento.\n",
    "- **Consejo:** Observa desbalance (e.g., 60% no sobrevivieron). Usa `stratify` en split.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Clases desbalanceadas, valores faltantes en 'age', 'embarked', 'deck'. Variables como 'sex' y 'pclass' influyen en supervivencia.\n",
    "\n",
    "### 4.2 An√°lisis Exploratorio y Feature Engineering\n",
    "\n",
    "Visualizamos relaciones clave y creamos insights iniciales para el Titanic.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **Gr√°ficos de barras:** Para variables categ√≥ricas como 'pclass', 'sex', 'embarked', 'sibsp' vs supervivencia.\n",
    "- **Boxplots:** Para 'age' y 'fare' vs supervivencia, para ver distribuciones.\n",
    "- **Insights:** Basados en gr√°ficos, notamos patrones como mujeres y clases altas con mayor supervivencia.\n",
    "- **¬øPor qu√© estos gr√°ficos?** Para entender factores de supervivencia y planificar feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis exploratorio Titanic\n",
    "\n",
    "# Crear figura con subplots para visualizaciones\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Supervivencia por clase (Pclass)\n",
    "survived_class = df_titanic.groupby(['Pclass', 'Survived']).size().unstack()  # Agrupar y contar\n",
    "survived_class.plot(kind='bar', ax=axes[0, 0])  # Gr√°fico de barras\n",
    "axes[0, 0].set_title('Supervivencia por Clase')\n",
    "axes[0, 0].set_xlabel('Clase')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# 2. Supervivencia por sexo\n",
    "survived_sex = df_titanic.groupby(['Sex', 'Survived']).size().unstack()\n",
    "survived_sex.plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Supervivencia por Sexo')\n",
    "axes[0, 1].set_xlabel('Sexo')\n",
    "\n",
    "# 3. Edad vs Supervivencia\n",
    "df_titanic.boxplot(column='Age', by='Survived', ax=axes[0, 2])  # Boxplot por supervivencia\n",
    "axes[0, 2].set_title('Edad vs Supervivencia')\n",
    "\n",
    "# 4. Tarifa vs Supervivencia\n",
    "df_titanic.boxplot(column='Fare', by='Survived', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Tarifa vs Supervivencia')\n",
    "\n",
    "# 5. Supervivencia por puerto de embarque\n",
    "if 'Embarked' in df_titanic.columns:\n",
    "    survived_embarked = df_titanic.groupby(['Embarked', 'Survived']).size().unstack()\n",
    "    survived_embarked.plot(kind='bar', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Supervivencia por Puerto de Embarque')\n",
    "\n",
    "# 6. Supervivencia por n√∫mero de familiares (SibSp)\n",
    "if 'SibSp' in df_titanic.columns:\n",
    "    survived_sibsp = df_titanic.groupby(['SibSp', 'Survived']).size().unstack()\n",
    "    survived_sibsp.plot(kind='bar', ax=axes[1, 2])\n",
    "    axes[1, 2].set_title('Supervivencia por Hermanos/Esposos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir insights iniciales\n",
    "print(\"üîç INSIGHTS INICIALES TITANIC:\")\n",
    "print(\"‚Ä¢ Las mujeres tuvieron mayor tasa de supervivencia\")\n",
    "print(\"‚Ä¢ La clase social influy√≥ significativamente\")\n",
    "print(\"‚Ä¢ Los ni√±os tuvieron prioridad en los botes salvavidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be8196",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `plt.subplots(2, 3):` Crea 6 gr√°ficos. **¬øPor qu√©?** Para analizar m√∫ltiples variables.\n",
    "- `groupby(['pclass', 'survived']).size().unstack():` Cuenta por clase y supervivencia. **¬øPor qu√©?** Para ver tasas de supervivencia por categor√≠a.\n",
    "- `boxplot(column='age', by='survived'):` Distribuciones de edad por supervivencia. **¬øPor qu√©?** Para ver si edad afecta supervivencia.\n",
    "- **Consejo:** Observa patrones como mujeres y clases altas con mayor supervivencia. Usa esto para feature engineering.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Mujeres y clases altas con mayor supervivencia. Edad y tarifa podr√≠an diferir por supervivencia.\n",
    "\n",
    "### 4.3 Preprocesamiento Avanzado\n",
    "\n",
    "Preparamos los datos del Titanic con feature engineering: manejamos faltantes, creamos nuevas caracter√≠sticas y codificamos categ√≥ricas.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **Manejar faltantes:** Rellenamos 'age' con mediana, 'embarked' con moda, eliminamos 'deck' (muchos faltantes).\n",
    "- **Feature engineering:** Creamos 'family_size' (tama√±o familia), 'is_alone' (si viaja solo), 'title' (t√≠tulo de nombre).\n",
    "- **Codificar categ√≥ricas:** Usamos LabelEncoder para 'sex', 'embarked', 'title'.\n",
    "- **Seleccionar features:** Elegimos variables relevantes.\n",
    "- **Dividir y escalar:** Similar a antes, con estratificaci√≥n por desbalance.\n",
    "- **¬øPor qu√© feature engineering?** Para mejorar el modelo con variables derivadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering para Titanic\n",
    "\n",
    "print(\"üîß PREPROCESAMIENTO AVANZADO - TITANIC\")\n",
    "\n",
    "# Crear copia para no modificar original\n",
    "df_titanic_clean = df_titanic.copy()\n",
    "\n",
    "# 1. Manejar valores faltantes\n",
    "df_titanic_clean['Age'].fillna(df_titanic_clean['Age'].median(), inplace=True)  # Rellenar edad con mediana\n",
    "df_titanic_clean['Embarked'].fillna(df_titanic_clean['Embarked'].mode()[0], inplace=True)  # Rellenar embarked con moda\n",
    "df_titanic_clean.drop(columns=['Deck'], inplace=True, errors='ignore')  # Eliminar 'deck' (muchos faltantes)\n",
    "\n",
    "# 2. Crear nuevas caracter√≠sticas\n",
    "df_titanic_clean['Family_Size'] = df_titanic_clean['SibSp'] + df_titanic_clean['Parch'] + 1  # Tama√±o familia\n",
    "df_titanic_clean['Is_Alone'] = (df_titanic_clean['Family_Size'] == 1).astype(int)  # 1 si solo, 0 si no\n",
    "df_titanic_clean['Title'] = df_titanic_clean['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)  # Extraer t√≠tulo\n",
    "\n",
    "# Simplificar t√≠tulos\n",
    "title_mapping = {'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n",
    "                 'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',\n",
    "                 'Mlle': 'Miss', 'Countess': 'Rare', 'Ms': 'Miss', 'Lady': 'Rare',\n",
    "                 'Jonkheer': 'Rare', 'Don': 'Rare', 'Dona': 'Rare', 'Mme': 'Mrs',\n",
    "                 'Capt': 'Rare', 'Sir': 'Rare'}\n",
    "df_titanic_clean['Title'] = df_titanic_clean['Title'].map(title_mapping)  # Mapear t√≠tulos\n",
    "\n",
    "# 3. Codificar variables categ√≥ricas\n",
    "label_encoders = {}\n",
    "categorical_cols = ['Sex', 'Embarked', 'Title']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_titanic_clean.columns:\n",
    "        le = LabelEncoder()  # Inicializar encoder\n",
    "        df_titanic_clean[col] = le.fit_transform(df_titanic_clean[col].astype(str))  # Codificar\n",
    "        label_encoders[col] = le  # Guardar encoder\n",
    "\n",
    "# 4. Seleccionar caracter√≠sticas finales\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked',\n",
    "            'Family_Size', 'Is_Alone', 'Title']\n",
    "X_titanic = df_titanic_clean[features]  # X: features seleccionadas\n",
    "y_titanic = df_titanic_clean['Survived']  # y: supervivencia\n",
    "\n",
    "# 5. Dividir datos\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(\n",
    "    X_titanic, y_titanic, test_size=0.3, random_state=42, stratify=y_titanic  # stratify por desbalance\n",
    ")\n",
    "\n",
    "# 6. Escalar para SVM\n",
    "scaler_titanic = StandardScaler()  # Inicializar escalador\n",
    "X_titanic_train_scaled = scaler_titanic.fit_transform(X_titanic_train)  # Ajustar y transformar train\n",
    "X_titanic_test_scaled = scaler_titanic.transform(X_titanic_test)  # Solo transformar test\n",
    "\n",
    "# Confirmar preparaci√≥n\n",
    "print(\"‚úÖ DATOS TITANIC PREPARADOS:\")\n",
    "print(f\"Caracter√≠sticas usadas: {features}\")\n",
    "print(f\"Entrenamiento: {X_titanic_train.shape[0]} muestras\")\n",
    "print(f\"Prueba: {X_titanic_test.shape[0]} muestras\")\n",
    "print(f\"Proporci√≥n supervivencia: {y_titanic_train.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f405bd",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `fillna con median/mode:` Para 'age' (num√©rica) y 'embarked' (categ√≥rica). **¬øPor qu√©?** Mediana para num√©rica, moda para categ√≥rica.\n",
    "- `drop('deck'):` Elimina columna con muchos faltantes. **¬øPor qu√©?** Evita ruido.\n",
    "- `family_size = sibsp + parch + 1:` Incluye al pasajero. **¬øPor qu√©?** Para capturar efecto de familia.\n",
    "- `is_alone:` Binaria para si viaja solo. **¬øPor qu√©?** Podr√≠a afectar supervivencia.\n",
    "- `title:` Extrae de 'name'. **¬øPor qu√©?** T√≠tulos como 'Mr' o 'Mrs' indican g√©nero/edad.\n",
    "- `LabelEncoder:` Convierte categ√≥ricas a n√∫meros. **¬øPor qu√©?** Modelos necesitan n√∫meros.\n",
    "- `features:` Lista de variables finales. **¬øPor qu√©?** Para enfocarse en relevantes.\n",
    "- **Consejo:** Feature engineering mejora el modelo. Experimenta con m√°s variables.\n",
    "\n",
    "**¬øQu√© sigue?** Entrenamos los modelos con estos datos preparados.\n",
    "\n",
    "### 4.4 Modelo: √Årbol de Decisi√≥n para Titanic\n",
    "\n",
    "Entrenamos un √Årbol de Decisi√≥n para predecir supervivencia en el Titanic, con par√°metros fijos para simplicidad.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **DecisionTreeClassifier:** Modelo para clasificaci√≥n con datos mixtos.\n",
    "- **Par√°metros fijos:** max_depth=5, etc., para evitar overfitting en datos peque√±os.\n",
    "- **M√©tricas:** Mismas que antes.\n",
    "- **Visualizar √°rbol:** Muestra los primeros 3 niveles para interpretabilidad.\n",
    "- **Importancia de caracter√≠sticas:** Muestra qu√© variables son m√°s importantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √Årbol de Decisi√≥n para Titanic\n",
    "\n",
    "print(\"üå≥ ENTRENANDO √ÅRBOL DE DECISI√ìN (TITANIC)\")\n",
    "\n",
    "# Inicializar modelo con par√°metros fijos\n",
    "tree_titanic = DecisionTreeClassifier(\n",
    "    max_depth=5,  # Profundidad m√°xima para evitar overfitting\n",
    "    min_samples_split=10,  # M√≠nimo muestras para split\n",
    "    min_samples_leaf=5,  # M√≠nimo muestras en hoja\n",
    "    random_state=42  # Para reproducibilidad\n",
    ")\n",
    "tree_titanic.fit(X_titanic_train, y_titanic_train)  # Entrenar\n",
    "\n",
    "# Predicciones\n",
    "y_pred_tree_titanic = tree_titanic.predict(X_titanic_test)  # Predecir en test\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy_tree_titanic = accuracy_score(y_titanic_test, y_pred_tree_titanic)  # Exactitud\n",
    "precision_tree_titanic = precision_score(y_titanic_test, y_pred_tree_titanic)  # Precisi√≥n\n",
    "recall_tree_titanic = recall_score(y_titanic_test, y_pred_tree_titanic)  # Recall\n",
    "f1_tree_titanic = f1_score(y_titanic_test, y_pred_tree_titanic)  # F1-Score\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"üìä RESULTADOS √ÅRBOL - TITANIC:\")\n",
    "print(f\" Exactitud: {accuracy_tree_titanic:.3f}\")\n",
    "print(f\" Precisi√≥n: {precision_tree_titanic:.3f}\")\n",
    "print(f\" Recall: {recall_tree_titanic:.3f}\")\n",
    "print(f\" F1-Score: {f1_tree_titanic:.3f}\")\n",
    "\n",
    "# Visualizar √°rbol (versi√≥n simplificada)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_titanic,  # El modelo entrenado\n",
    "          feature_names=features,  # Nombres de caracter√≠sticas\n",
    "          class_names=['No Sobrevivi√≥', 'Sobrevivi√≥'],  # Nombres de clases\n",
    "          filled=True,  # Colorear nodos por clase\n",
    "          rounded=True,  # Bordes redondeados\n",
    "          fontsize=10,  # Tama√±o de fuente\n",
    "          max_depth=3)  # Mostrar solo primeros 3 niveles para claridad\n",
    "plt.title('√Årbol de Decisi√≥n - Titanic (Primeros 3 niveles)', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Importancia de caracter√≠sticas\n",
    "importancia_titanic = pd.DataFrame({\n",
    "    'caracteristica': features,  # Nombres de features\n",
    "    'importancia': tree_titanic.feature_importances_  # Importancia calculada\n",
    "}).sort_values('importancia', ascending=False)  # Ordenar de mayor a menor\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importancia_titanic['caracteristica'], importancia_titanic['importancia'])  # Gr√°fico horizontal\n",
    "plt.xlabel('Importancia')  # Etiqueta X\n",
    "plt.title('Importancia de Caracter√≠sticas - Titanic')\n",
    "plt.gca().invert_yaxis()  # Invertir Y para que la m√°s importante est√© arriba\n",
    "plt.grid(True, alpha=0.3, axis='x')  # Grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb07d0",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `DecisionTreeClassifier con par√°metros fijos:** No usamos GridSearch para simplicidad. **¬øPor qu√©?\\*\\* Para enfocarnos en feature engineering.\n",
    "- `fit y predict:\\*\\* Entrena y predice.\n",
    "- `m√©tricas:\\*\\* Mismas que antes.\n",
    "- `plot_tree:** Visualiza el √°rbol. **¬øPor qu√© max_depth=3?\\*\\* Para no sobrecargar el gr√°fico.\n",
    "- `feature*importances*:** Importancia basada en reducci√≥n de error. **¬øPor qu√© visualizar?\\*\\* Para ver qu√© features son clave (e.g., 'sex' y 'pclass').\n",
    "- **Consejo:** Interpreta el √°rbol: cada nodo es una decisi√≥n basada en una feature.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Exactitud >0.8, importancia alta en 'sex' y 'pclass'. El √°rbol muestra reglas como \"Si es mujer, sobrevivi√≥\".\n",
    "\n",
    "### 4.5 Modelo: SVM para Titanic\n",
    "\n",
    "Entrenamos un SVM para predecir supervivencia en el Titanic, con par√°metros fijos.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **SVC:** Modelo para clasificaci√≥n con datos mixtos y escalados.\n",
    "- **Par√°metros fijos:** C=1.0, kernel='rbf', gamma='scale' para simplicidad.\n",
    "- **M√©tricas:** Mismas que el √Årbol.\n",
    "- **Matrices de confusi√≥n:** Comparativas con el √Årbol, colores diferentes para distinguir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM para Titanic\n",
    "\n",
    "print(\"üéØ ENTRENANDO SVM (TITANIC)\")\n",
    "\n",
    "# Inicializar modelo con par√°metros fijos\n",
    "svm_titanic = SVC(\n",
    "    C=1.0,  # Penalizaci√≥n por errores\n",
    "    kernel='rbf',  # Kernel no lineal\n",
    "    gamma='scale',  # Influencia de puntos\n",
    "    random_state=42  # Para reproducibilidad\n",
    ")\n",
    "svm_titanic.fit(X_titanic_train_scaled, y_titanic_train)  # Entrenar con datos escalados\n",
    "\n",
    "# Predicciones\n",
    "y_pred_svm_titanic = svm_titanic.predict(X_titanic_test_scaled)  # Predecir en test escalado\n",
    "\n",
    "# Calcular m√©tricas\n",
    "accuracy_svm_titanic = accuracy_score(y_titanic_test, y_pred_svm_titanic)  # Exactitud\n",
    "precision_svm_titanic = precision_score(y_titanic_test, y_pred_svm_titanic)  # Precisi√≥n\n",
    "recall_svm_titanic = recall_score(y_titanic_test, y_pred_svm_titanic)  # Recall\n",
    "f1_svm_titanic = f1_score(y_titanic_test, y_pred_svm_titanic)  # F1-Score\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"üìä RESULTADOS SVM - TITANIC:\")\n",
    "print(f\" Exactitud: {accuracy_svm_titanic:.3f}\")\n",
    "print(f\" Precisi√≥n: {precision_svm_titanic:.3f}\")\n",
    "print(f\" Recall: {recall_svm_titanic:.3f}\")\n",
    "print(f\" F1-Score: {f1_svm_titanic:.3f}\")\n",
    "\n",
    "# Matrices de confusi√≥n comparativas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Matriz para √Årbol\n",
    "cm_tree_titanic = confusion_matrix(y_titanic_test, y_pred_tree_titanic)  # Calcular para √Årbol\n",
    "sns.heatmap(cm_tree_titanic, annot=True, fmt='d', cmap='Blues', ax=axes[0],  # Colores azules\n",
    "            xticklabels=['No Sobrevivi√≥', 'Sobrevivi√≥'],\n",
    "            yticklabels=['No Sobrevivi√≥', 'Sobrevivi√≥'])\n",
    "axes[0].set_title('Matriz Confusi√≥n - √Årbol de Decisi√≥n')\n",
    "axes[0].set_ylabel('Real')\n",
    "axes[0].set_xlabel('Predicci√≥n')\n",
    "\n",
    "# Matriz para SVM\n",
    "cm_svm_titanic = confusion_matrix(y_titanic_test, y_pred_svm_titanic)  # Calcular para SVM\n",
    "sns.heatmap(cm_svm_titanic, annot=True, fmt='d', cmap='Reds', ax=axes[1],  # Colores rojos\n",
    "            xticklabels=['No Sobrevivi√≥', 'Sobrevivi√≥'],\n",
    "            yticklabels=['No Sobrevivi√≥', 'Sobrevivi√≥'])\n",
    "axes[1].set_title('Matriz Confusi√≥n - SVM')\n",
    "axes[1].set_ylabel('Real')\n",
    "axes[1].set_xlabel('Predicci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3ccb1",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `SVC con par√°metros fijos:** No usamos GridSearch para simplicidad. **¬øPor qu√©?\\*\\* Para comparar con el √Årbol r√°pidamente.\n",
    "- `fit con datos escalados:** SVM requiere escalado. **¬øPor qu√©?\\*\\* Para m√°rgenes correctos.\n",
    "- `predict:\\*\\* Clasifica en 0 o 1.\n",
    "- `m√©tricas:\\*\\* Mismas que el √Årbol.\n",
    "- `confusion_matrix:** Dos matrices lado a lado. **¬øPor qu√© cmap diferentes?\\*\\* Para distinguir modelos.\n",
    "- **Consejo:** Compara matrices. SVM podr√≠a tener menos falsos positivos.\n",
    "\n",
    "**¬øQu√© esperamos ver?** Exactitud similar al √Årbol, matrices con aciertos en diagonal.\n",
    "\n",
    "### 4.6 Comparaci√≥n Final y An√°lisis\n",
    "\n",
    "Comparamos los modelos para Titanic y resumimos todos los ejercicios.\n",
    "\n",
    "**Explicaci√≥n:**\n",
    "\n",
    "- **DataFrame de resultados:** Tabla con m√©tricas para Titanic.\n",
    "- **Resumen final:** DataFrame con m√©tricas principales de todos los datasets.\n",
    "- **Gr√°ficos de barras:** Uno por dataset para comparar modelos.\n",
    "- **Conclusiones:** Basadas en resultados, destacamos ventajas y recomendaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n final todos los modelos\n",
    "\n",
    "print(\"üìä COMPARACI√ìN FINAL - TITANIC\")\n",
    "\n",
    "# Crear DataFrame con m√©tricas para Titanic\n",
    "resultados_titanic = pd.DataFrame({\n",
    "    'Modelo': ['√Årbol de Decisi√≥n', 'SVM'],\n",
    "    'Exactitud': [accuracy_tree_titanic, accuracy_svm_titanic],  # Exactitud\n",
    "    'Precisi√≥n': [precision_tree_titanic, precision_svm_titanic],  # Precisi√≥n\n",
    "    'Recall': [recall_tree_titanic, recall_svm_titanic],  # Recall\n",
    "    'F1-Score': [f1_tree_titanic, f1_svm_titanic]  # F1-Score\n",
    "})\n",
    "\n",
    "print(resultados_titanic)  # Mostrar tabla\n",
    "\n",
    "# Resumen de todos los ejercicios\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ RESUMEN FINAL DE TODOS LOS EJERCICIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame con m√©tricas principales de cada modelo y dataset\n",
    "resumen_final = pd.DataFrame({\n",
    "    'Dataset': ['California Housing', 'California Housing', 'Diabetes', 'Diabetes', 'Titanic', 'Titanic'],\n",
    "    'Modelo': ['√Årbol', 'SVM', '√Årbol', 'SVM', '√Årbol', 'SVM'],\n",
    "    'M√©trica Principal': [r2_tree, r2_svm, accuracy_tree, accuracy_svm, accuracy_tree_titanic, accuracy_svm_titanic],  # R¬≤ para regresi√≥n, Exactitud para clasificaci√≥n\n",
    "    'Valor': [r2_tree, r2_svm, accuracy_tree, accuracy_svm, accuracy_tree_titanic, accuracy_svm_titanic]  # Valores num√©ricos\n",
    "})\n",
    "\n",
    "print(resumen_final)  # Mostrar resumen\n",
    "\n",
    "# Visualizaci√≥n resumen final\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # 1 fila, 3 columnas\n",
    "\n",
    "# California Housing (R¬≤)\n",
    "axes[0].bar(['√Årbol', 'SVM'], [r2_tree, r2_svm], color=['skyblue', 'lightcoral'])\n",
    "axes[0].set_title('California Housing\\n(R¬≤ Score)')\n",
    "axes[0].set_ylabel('R¬≤')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "for i, v in enumerate([r2_tree, r2_svm]):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')  # Texto en barras\n",
    "\n",
    "# Diabetes (Exactitud)\n",
    "axes[1].bar(['√Årbol', 'SVM'], [accuracy_tree, accuracy_svm], color=['skyblue', 'lightcoral'])\n",
    "axes[1].set_title('Diabetes\\n(Exactitud)')\n",
    "axes[1].set_ylabel('Exactitud')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "for i, v in enumerate([accuracy_tree, accuracy_svm]):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Titanic (Exactitud)\n",
    "axes[2].bar(['√Årbol', 'SVM'], [accuracy_tree_titanic, accuracy_svm_titanic], color=['skyblue', 'lightcoral'])\n",
    "axes[2].set_title('Titanic\\n(Exactitud)')\n",
    "axes[2].set_ylabel('Exactitud')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "for i, v in enumerate([accuracy_tree_titanic, accuracy_svm_titanic]):\n",
    "    axes[2].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Conclusiones generales\n",
    "print(\"\"\"\n",
    "üí° CONCLUSIONES GENERALES:\n",
    "\n",
    "üå≥ √ÅRBOLES DE DECISI√ìN:\n",
    "‚Ä¢ Ventajas: Interpretables, no necesitan escalado, manejan caracter√≠sticas mixtas\n",
    "‚Ä¢ Desventajas: Propensos a overfitting, inestables\n",
    "‚Ä¢ Mejor en: Titanic (con feature engineering)\n",
    "\n",
    "üéØ SVM:\n",
    "‚Ä¢ Ventajas: Buen rendimiento con datos complejos, robustos a outliers\n",
    "‚Ä¢ Desventajas: Necesitan escalado, lentos con muchos datos, dif√≠ciles de interpretar\n",
    "‚Ä¢ Mejor en: Diabetes (datos num√©ricos limpios)\n",
    "\n",
    "üìä POR DATASET:\n",
    "‚Ä¢ California Housing: Ambos modelos similares, problema de regresi√≥n\n",
    "‚Ä¢ Diabetes: SVM ligeramente mejor en clasificaci√≥n\n",
    "‚Ä¢ Titanic: √Årbol mejor gracias a la interpretabilidad y feature engineering\n",
    "\n",
    "üöÄ RECOMENDACIONES:\n",
    "‚Ä¢ Usar √°rboles cuando necesites explicar las decisiones\n",
    "‚Ä¢ Usar SVM cuando la precisi√≥n sea prioridad y tengas datos escalados\n",
    "‚Ä¢ Siempre hacer feature engineering y preprocesamiento adecuado\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a3f2f",
   "metadata": {},
   "source": [
    "\n",
    "**Explicaci√≥n del c√≥digo:**\n",
    "\n",
    "- `resultados_titanic:** DataFrame para Titanic. **¬øPor qu√©?\\*\\* Para comparar m√©tricas.\n",
    "- `resumen_final:** DataFrame con todos los datasets. **¬øPor qu√©?\\*\\* Para ver overview.\n",
    "- `plt.subplots(1, 3):** Tres gr√°ficos para cada dataset. **¬øPor qu√©?\\*\\* Para comparar visualmente.\n",
    "- `axes[0].bar, etc.:** Gr√°fico por dataset. **¬øPor qu√© colores?\\*\\* Para consistencia.\n",
    "- `text:** A√±ade valores. **¬øPor qu√©?\\*\\* Para precisi√≥n.\n",
    "- **Conclusiones:** Texto con ventajas/desventajas. **¬øPor qu√©?** Para guiar al usuario.\n",
    "\n",
    "**¬øQu√© esperamos ver?** √Årbol mejor en Titanic por interpretabilidad, SVM en Diabetes por precisi√≥n. Recomendaciones basadas en resultados.\n",
    "\n",
    "üß™ EJERCICIOS ADICIONALES PARA PRACTICAR\n",
    "\n",
    "üéØ EJERCICIO 4: OPTIMIZACI√ìN AVANZADA\n",
    "\n",
    "1. Mejora el modelo de Titanic:\n",
    "\n",
    "   - Prueba diferentes par√°metros para el √°rbol\n",
    "   - Experimenta con otros kernels en SVM\n",
    "   - A√±ade m√°s feature engineering (edad en categor√≠as, etc.)\n",
    "\n",
    "2. Ensemble Methods:\n",
    "\n",
    "   - Prueba Random Forest en lugar de un solo √°rbol\n",
    "   - Compara con los resultados obtenidos\n",
    "\n",
    "3. An√°lisis de Errores:\n",
    "   - ¬øQu√© pasajeros clasifica mal el modelo?\n",
    "   - ¬øHay patrones en los errores?\n",
    "\n",
    "üîç EJERCICIO 5: INTERPRETACI√ìN DE MODELOS\n",
    "\n",
    "1. Para el √°rbol de Titanic:\n",
    "\n",
    "   - Explica 3 reglas de decisi√≥n importantes\n",
    "   - ¬øQu√© caracter√≠sticas son m√°s importantes?\n",
    "\n",
    "2. Para SVM:\n",
    "   - ¬øPor qu√© crees que funcion√≥ mejor en Diabetes?\n",
    "   - ¬øC√≥mo afecta el par√°metro C a los resultados?\n",
    "\n",
    "üìà EJERCICIO 6: VALIDACI√ìN CRUZADA\n",
    "\n",
    "1. Implementa k-fold cross validation en todos los modelos\n",
    "2. Compara los resultados con la divisi√≥n simple train/test\n",
    "3. Analiza la varianza de los resultados\n",
    "\n",
    "üöÄ EJERCICIO 7: APLICACI√ìN A NUEVOS DATOS\n",
    "\n",
    "1. Encuentra otro dataset de clasificaci√≥n (ej: Iris, Wine)\n",
    "2. Aplica el mismo proceso completo\n",
    "3. Compara tus resultados con los obtenidos aqu√≠\n",
    "   \"\"\"\n",
    "\n",
    "üéâ ¬°FELICITACIONES POR COMPLETAR LOS EJERCICIOS!\n",
    "\n",
    "Has aplicado exitosamente:\n",
    "‚Ä¢ √Årboles de Decisi√≥n para regresi√≥n y clasificaci√≥n\n",
    "‚Ä¢ SVM para regresi√≥n y clasificaci√≥n  \n",
    "‚Ä¢ Preprocesamiento y feature engineering\n",
    "‚Ä¢ Evaluaci√≥n y comparaci√≥n de modelos\n",
    "‚Ä¢ Tres datasets del mundo real\n",
    "\n",
    "¬°Sigue practicando y explorando! üöÄ\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
