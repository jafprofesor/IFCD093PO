{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7617b67",
   "metadata": {},
   "source": [
    "# Regresi√≥n Lineal con el Dataset de Diabetes \n",
    "\n",
    "## üìö Contenido del Curso\n",
    "\n",
    "Este notebook comprende una gu√≠a educativa completa sobre regresi√≥n lineal con 3 partes:\n",
    "\n",
    "1. **Parte 1**: Regresi√≥n Lineal Simple B√°sica\n",
    "2. **Parte 2**: Regresi√≥n Lineal con EDA (An√°lisis Exploratorio de Datos)\n",
    "3. **Parte 3**: Comparaci√≥n de Modelos - Lineal, Polin√≥mico y Logar√≠tmico\n",
    "\n",
    "Aprenderemos desde lo m√°s b√°sico hasta t√©cnicas avanzadas de modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a483e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 1: Regresi√≥n Lineal Simple B√°sica\n",
    "\n",
    "Comenzaremos con un ejercicio simple usando una sola caracter√≠stica para predecir la progresi√≥n de la diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a582b9",
   "metadata": {},
   "source": [
    "## Paso 1: Importar las librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importamos las librer√≠as necesarias\n",
    "import numpy as np                      # Para manejo num√©rico de arreglos\n",
    "import pandas as pd                     # Para manejo de estructuras tipo DataFrame\n",
    "import matplotlib.pyplot as plt         # Para crear gr√°ficas\n",
    "from sklearn import datasets, linear_model  # Para cargar datos y crear el modelo\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Para evaluar el modelo\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bbc3a",
   "metadata": {},
   "source": [
    "## Paso 2: Cargar el dataset de Diabetes\n",
    "\n",
    "El dataset contiene informaci√≥n m√©dica de 442 pacientes con diferentes par√°metros (edad, IMC, presi√≥n, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cargamos el dataset real de diabetes desde scikit-learn\n",
    "# Este dataset contiene informaci√≥n m√©dica de pacientes.\n",
    "# Cada fila representa un paciente con distintos par√°metros (edad, IMC, presi√≥n, etc.)\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Mostramos el tama√±o original del dataset\n",
    "print(\"Dimensiones originales de X:\", diabetes_X.shape)  # (442, 10): 442 muestras y 10 caracter√≠sticas\n",
    "print(\"Dimensiones de y:\", diabetes_y.shape)              # Vector de 442 valores objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44682f0",
   "metadata": {},
   "source": [
    "## Paso 3: Seleccionar una caracter√≠stica\n",
    "\n",
    "Para mantener el ejemplo simple, usaremos solo una caracter√≠stica (la tercera: √≠ndice 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516622c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Usamos solo UNA caracter√≠stica (por ejemplo la tercera: √≠ndice 2)\n",
    "# As√≠ lo convertimos en un problema de regresi√≥n lineal simple (una sola variable)\n",
    "diabetes_X = diabetes_X[:, np.newaxis, 2]  # np.newaxis agrega una dimensi√≥n\n",
    "print(\"Nueva forma de X:\", diabetes_X.shape)  # Ahora solo una columna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f14a31",
   "metadata": {},
   "source": [
    "## Paso 4: Dividir en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dividimos los datos en entrenamiento y prueba\n",
    "# Usamos las primeras 422 observaciones para entrenar y las √∫ltimas 20 para probar\n",
    "diabetes_X_train = diabetes_X[:-20]  # Datos de entrenamiento\n",
    "diabetes_X_test = diabetes_X[-20:]   # Datos de prueba\n",
    "diabetes_y_train = diabetes_y[:-20]  # Etiquetas de entrenamiento\n",
    "diabetes_y_test = diabetes_y[-20:]   # Etiquetas de prueba\n",
    "\n",
    "print(f\"Datos de entrenamiento: {len(diabetes_X_train)} muestras\")\n",
    "print(f\"Datos de test: {len(diabetes_X_test)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270821c",
   "metadata": {},
   "source": [
    "## Paso 5: Crear y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Creamos el modelo de regresi√≥n lineal\n",
    "model = linear_model.LinearRegression()  # Creamos el objeto del modelo\n",
    "model.fit(diabetes_X_train, diabetes_y_train)  # Entrenamos el modelo con los datos\n",
    "\n",
    "print(\"‚úì Modelo entrenado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7d232",
   "metadata": {},
   "source": [
    "## Paso 6: Hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4853c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Realizamos predicciones con los datos de prueba\n",
    "diabetes_y_pred = model.predict(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d4af0",
   "metadata": {},
   "source": [
    "## Paso 7: Evaluar el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluamos el rendimiento del modelo\n",
    "print(\"‚ïî\" + \"‚ïê\" * 48 + \"‚ïó\")\n",
    "print(\"‚ïë\" + \"EVALUACI√ìN DEL MODELO LINEAL SIMPLE\".center(48) + \"‚ïë\")\n",
    "print(\"‚ïö\" + \"‚ïê\" * 48 + \"‚ïù\")\n",
    "print(f\"Coeficiente (pendiente): {model.coef_[0]:.4f}\")\n",
    "print(\"  ‚Üí Indica la relaci√≥n entre la variable independiente y la dependiente\")\n",
    "print(f\"\\nIntercepto: {model.intercept_:.4f}\")\n",
    "print(\"  ‚Üí Valor de la recta cuando X=0\")\n",
    "\n",
    "mse = mean_squared_error(diabetes_y_test, diabetes_y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(diabetes_y_test, diabetes_y_pred)\n",
    "\n",
    "print(f\"\\nError cuadr√°tico medio (MSE): {mse:.4f}\")\n",
    "print(f\"Ra√≠z del error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Coeficiente de determinaci√≥n (R¬≤): {r2:.4f}\")\n",
    "print(\"‚ïê\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a048136",
   "metadata": {},
   "source": [
    "## Paso 8: Visualizar los resultados\n",
    "\n",
    "Graficaremos los puntos reales (en negro) y la l√≠nea ajustada por el modelo (en azul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c349c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Visualizamos los resultados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\", label=\"Datos reales\", s=80)\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=2, label=\"Ajuste lineal\")\n",
    "plt.xlabel(\"Variable explicativa (caracter√≠stica del paciente)\", fontsize=11)\n",
    "plt.ylabel(\"Progresi√≥n de la enfermedad\", fontsize=11)\n",
    "plt.title(\"Regresi√≥n lineal simple - Dataset Diabetes\", fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab31b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 2: Regresi√≥n Lineal con EDA (An√°lisis Exploratorio de Datos)\n",
    "\n",
    "Ahora exploraremos el dataset m√°s a fondo usando an√°lisis exploratorio antes de modelar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c661e4",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar dataset como DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importar librer√≠as adicionales\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 2. Cargar dataset real desde scikit-learn\n",
    "# 'as_frame=True' devuelve un DataFrame con nombres de columnas y el target separado\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "df = diabetes.frame  # Contiene 10 variables + target ('y')\n",
    "\n",
    "print(\"‚úì Primeras filas del dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa866b",
   "metadata": {},
   "source": [
    "## Paso 2: Informaci√≥n general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35184f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Informaci√≥n general del dataset\n",
    "print(\"Dimensiones del dataset:\", df.shape)     # 442 registros, 11 columnas (10 features + target)\n",
    "print(\"\\nColumnas disponibles:\", df.columns.tolist())\n",
    "print(\"\\nDescripci√≥n estad√≠stica general:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529d932",
   "metadata": {},
   "source": [
    "## Paso 3: Renombrar variable objetivo para claridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Renombramos la variable objetivo para m√°s claridad\n",
    "df.rename(columns={\"target\": \"disease_progression\"}, inplace=True)\n",
    "print(\"‚úì Variable objetivo renombrada a 'disease_progression'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3277b3fa",
   "metadata": {},
   "source": [
    "## Paso 4: Visualizar distribuciones de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee281c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualizar distribuciones de las variables m√°s importantes\n",
    "# Seleccionamos algunas para analizar su comportamiento\n",
    "cols_to_plot = ['bmi', 'bp', 's5', 'disease_progression']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "df[cols_to_plot].hist(bins=20, figsize=(12, 6), color='lightblue', edgecolor='black')\n",
    "plt.suptitle(\"Distribuciones de variables relevantes\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c44d2d",
   "metadata": {},
   "source": [
    "## Paso 5: Matriz de correlaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0785249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Matriz de correlaci√≥n para ver relaciones entre variables\n",
    "corr = df.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", cbar=True)\n",
    "plt.title(\"Matriz de correlaci√≥n del dataset Diabetes\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar las variables m√°s correlacionadas con disease_progression\n",
    "print(\"\\nCorrelaciones con 'disease_progression':\")\n",
    "print(corr['disease_progression'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db62d11",
   "metadata": {},
   "source": [
    "## Paso 6: Seleccionar variable m√°s correlacionada\n",
    "\n",
    "BMI (Body Mass Index) suele tener alta correlaci√≥n con la progresi√≥n de la diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Elegimos la variable m√°s correlacionada con la enfermedad (disease_progression)\n",
    "# BMI (√≠ndice de masa corporal) suele tener alta correlaci√≥n con la progresi√≥n\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=df['bmi'], y=df['disease_progression'], color='steelblue', s=80, alpha=0.6)\n",
    "plt.title(\"Relaci√≥n entre 'BMI' y la progresi√≥n de la enfermedad\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"BMI (√çndice de masa corporal)\", fontsize=11)\n",
    "plt.ylabel(\"Progresi√≥n de la enfermedad\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91c4bd",
   "metadata": {},
   "source": [
    "## Paso 7: Preparar datos y entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Selecci√≥n de variable independiente (X) y dependiente (y)\n",
    "X = df[['bmi']]                   # Variable predictora\n",
    "y = df['disease_progression']     # Variable objetivo\n",
    "\n",
    "# 9. Divisi√≥n de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Datos de entrenamiento: {len(X_train)} muestras\")\n",
    "print(f\"Datos de test: {len(X_test)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c46f93",
   "metadata": {},
   "source": [
    "## Paso 8: Crear y entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Crear y entrenar modelo lineal\n",
    "model_eda = LinearRegression()\n",
    "model_eda.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úì Modelo entrenado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf987e3",
   "metadata": {},
   "source": [
    "## Paso 9: Evaluar coeficientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Evaluar coeficientes del modelo\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"COEFICIENTES DEL MODELO\")\n",
    "print(\"‚ïê\" * 50)\n",
    "print(f\"Intercepto (Œ≤‚ÇÄ): {model_eda.intercept_:.4f}\")\n",
    "print(f\"Coeficiente (Œ≤‚ÇÅ): {model_eda.coef_[0]:.4f}\")\n",
    "print(\"\\nEcuaci√≥n del modelo:\")\n",
    "print(f\"y = {model_eda.intercept_:.4f} + {model_eda.coef_[0]:.4f} * X\")\n",
    "print(\"‚ïê\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0214f",
   "metadata": {},
   "source": [
    "## Paso 10: Hacer predicciones y evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Realizar predicciones\n",
    "y_pred_eda = model_eda.predict(X_test)\n",
    "\n",
    "# 13. Evaluaci√≥n cuantitativa del modelo\n",
    "mse_eda = mean_squared_error(y_test, y_pred_eda)\n",
    "rmse_eda = np.sqrt(mse_eda)\n",
    "r2_eda = r2_score(y_test, y_pred_eda)\n",
    "\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"M√âTRICAS DE EVALUACI√ìN\")\n",
    "print(\"‚ïê\" * 50)\n",
    "print(f\"Error cuadr√°tico medio (MSE): {mse_eda:.4f}\")\n",
    "print(f\"Ra√≠z del error (RMSE): {rmse_eda:.4f}\")\n",
    "print(f\"Coeficiente de determinaci√≥n (R¬≤): {r2_eda:.4f}\")\n",
    "print(f\"\\nInterpretaci√≥n: El modelo explica {r2_eda*100:.2f}% de la varianza\")\n",
    "print(\"‚ïê\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4386ba",
   "metadata": {},
   "source": [
    "## Paso 11: Visualizaci√≥n del ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c88152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Visualizaci√≥n del ajuste del modelo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='gray', alpha=0.6, label='Datos reales', s=80)\n",
    "plt.plot(X_test.sort_values('bmi'), model_eda.predict(X_test.sort_values('bmi')), \n",
    "         color='red', linewidth=3, label='L√≠nea de regresi√≥n')\n",
    "plt.xlabel(\"BMI\", fontsize=11)\n",
    "plt.ylabel(\"Progresi√≥n de la enfermedad\", fontsize=11)\n",
    "plt.title(\"Regresi√≥n Lineal Simple: BMI vs Progresi√≥n\", fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42a987",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Parte 3: Comparaci√≥n de Modelos - Lineal, Polin√≥mico y Logar√≠tmico\n",
    "\n",
    "Ahora compararemos tres enfoques diferentes para ver cu√°l se ajusta mejor a los datos: lineal, logar√≠tmico y polin√≥mico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ab3f3",
   "metadata": {},
   "source": [
    "## Paso 1: Importar librer√≠as adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "print(\"‚úì Librer√≠as de comparaci√≥n de modelos cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67ba1b",
   "metadata": {},
   "source": [
    "## Paso 2: Preparar datos para comparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b372cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los datos ya est√°n preparados: X_train, X_test, y_train, y_test\n",
    "print(f\"Datos listos para comparaci√≥n:\")\n",
    "print(f\"  - Entrenamiento: {len(X_train)} muestras\")\n",
    "print(f\"  - Test: {len(X_test)} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf109587",
   "metadata": {},
   "source": [
    "## Paso 3: Modelo 1 - Regresi√≥n Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo lineal tradicional\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 1: REGRESI√ìN LINEAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train, y_train)\n",
    "y_pred_linear = model_linear.predict(X_test)\n",
    "\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "print(f\"Coeficiente: {model_linear.coef_[0]:.6f}\")\n",
    "print(f\"Intercepto: {model_linear.intercept_:.6f}\")\n",
    "print(f\"\\nMSE:  {mse_linear:.4f}\")\n",
    "print(f\"RMSE: {rmse_linear:.4f}\")\n",
    "print(f\"R¬≤:   {r2_linear:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd0fbf",
   "metadata": {},
   "source": [
    "## Paso 4: Modelo 2 - Regresi√≥n Polin√≥mica (Grado 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo polin√≥mico de grado 2\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 2: REGRESI√ìN POLIN√ìMICA (GRADO 2)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear features polin√≥micas de grado 2\n",
    "poly_features_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly2 = poly_features_2.fit_transform(X_train)\n",
    "X_test_poly2 = poly_features_2.transform(X_test)\n",
    "\n",
    "# Entrenar modelo\n",
    "model_poly2 = LinearRegression()\n",
    "model_poly2.fit(X_train_poly2, y_train)\n",
    "y_pred_poly2 = model_poly2.predict(X_test_poly2)\n",
    "\n",
    "mse_poly2 = mean_squared_error(y_test, y_pred_poly2)\n",
    "rmse_poly2 = np.sqrt(mse_poly2)\n",
    "r2_poly2 = r2_score(y_test, y_pred_poly2)\n",
    "\n",
    "print(f\"Coeficientes: {model_poly2.coef_}\")\n",
    "print(f\"Intercepto: {model_poly2.intercept_:.6f}\")\n",
    "print(f\"\\nMSE:  {mse_poly2:.4f}\")\n",
    "print(f\"RMSE: {rmse_poly2:.4f}\")\n",
    "print(f\"R¬≤:   {r2_poly2:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2f4f2",
   "metadata": {},
   "source": [
    "## Paso 5: Modelo 3 - Regresi√≥n Polin√≥mica (Grado 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo polin√≥mico de grado 3\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 3: REGRESI√ìN POLIN√ìMICA (GRADO 3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear features polin√≥micas de grado 3\n",
    "poly_features_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_train_poly3 = poly_features_3.fit_transform(X_train)\n",
    "X_test_poly3 = poly_features_3.transform(X_test)\n",
    "\n",
    "# Entrenar modelo\n",
    "model_poly3 = LinearRegression()\n",
    "model_poly3.fit(X_train_poly3, y_train)\n",
    "y_pred_poly3 = model_poly3.predict(X_test_poly3)\n",
    "\n",
    "mse_poly3 = mean_squared_error(y_test, y_pred_poly3)\n",
    "rmse_poly3 = np.sqrt(mse_poly3)\n",
    "r2_poly3 = r2_score(y_test, y_pred_poly3)\n",
    "\n",
    "print(f\"Coeficientes: {model_poly3.coef_}\")\n",
    "print(f\"Intercepto: {model_poly3.intercept_:.6f}\")\n",
    "print(f\"\\nMSE:  {mse_poly3:.4f}\")\n",
    "print(f\"RMSE: {rmse_poly3:.4f}\")\n",
    "print(f\"R¬≤:   {r2_poly3:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d7fa8",
   "metadata": {},
   "source": [
    "## Paso 6: Modelo 4 - Regresi√≥n Logar√≠tmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo logar√≠tmico\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELO 4: REGRESI√ìN LOGAR√çTMICA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Transformar X a logaritmo\n",
    "X_train_log = np.log(X_train + np.abs(X_train.min()) + 1)  # Evitar log(0)\n",
    "X_test_log = np.log(X_test + np.abs(X_test.min()) + 1)\n",
    "\n",
    "# Entrenar modelo\n",
    "model_log = LinearRegression()\n",
    "model_log.fit(X_train_log, y_train)\n",
    "y_pred_log = model_log.predict(X_test_log)\n",
    "\n",
    "mse_log = mean_squared_error(y_test, y_pred_log)\n",
    "rmse_log = np.sqrt(mse_log)\n",
    "r2_log = r2_score(y_test, y_pred_log)\n",
    "\n",
    "print(f\"Coeficiente: {model_log.coef_[0]:.6f}\")\n",
    "print(f\"Intercepto: {model_log.intercept_:.6f}\")\n",
    "print(f\"\\nMSE:  {mse_log:.4f}\")\n",
    "print(f\"RMSE: {rmse_log:.4f}\")\n",
    "print(f\"R¬≤:   {r2_log:.6f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26249830",
   "metadata": {},
   "source": [
    "## Paso 7: Tabla Comparativa de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo': ['Lineal', 'Polin√≥mico (Grado 2)', 'Polin√≥mico (Grado 3)', 'Logar√≠tmico'],\n",
    "    'MSE': [mse_linear, mse_poly2, mse_poly3, mse_log],\n",
    "    'RMSE': [rmse_linear, rmse_poly2, rmse_poly3, rmse_log],\n",
    "    'R¬≤': [r2_linear, r2_poly2, r2_poly3, r2_log]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Encontrar el mejor modelo\n",
    "best_model_idx = comparison_df['R¬≤'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Modelo']\n",
    "best_r2 = comparison_df.loc[best_model_idx, 'R¬≤']\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   R¬≤ = {best_r2:.6f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b317b",
   "metadata": {},
   "source": [
    "## Paso 8: Visualizaci√≥n Comparativa - Todos los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6dc1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n comparativa de todos los modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Comparaci√≥n de Modelos de Regresi√≥n', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Ordenar X_test para graficar l√≠neas suave\n",
    "X_test_sorted = np.sort(X_test.values.flatten())\n",
    "X_test_sorted_df = pd.DataFrame(X_test_sorted, columns=['bmi'])\n",
    "\n",
    "# 1. Modelo Lineal\n",
    "axes[0, 0].scatter(X_test, y_test, color='gray', alpha=0.6, s=50)\n",
    "y_pred_linear_sorted = model_linear.predict(X_test_sorted_df)\n",
    "axes[0, 0].plot(X_test_sorted, y_pred_linear_sorted, color='blue', linewidth=2.5, label=f'R¬≤={r2_linear:.4f}')\n",
    "axes[0, 0].set_title('Modelo Lineal', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('BMI')\n",
    "axes[0, 0].set_ylabel('Progresi√≥n')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Modelo Polin√≥mico Grado 2\n",
    "axes[0, 1].scatter(X_test, y_test, color='gray', alpha=0.6, s=50)\n",
    "X_test_sorted_poly2 = poly_features_2.transform(X_test_sorted_df)\n",
    "y_pred_poly2_sorted = model_poly2.predict(X_test_sorted_poly2)\n",
    "axes[0, 1].plot(X_test_sorted, y_pred_poly2_sorted, color='green', linewidth=2.5, label=f'R¬≤={r2_poly2:.4f}')\n",
    "axes[0, 1].set_title('Modelo Polin√≥mico (Grado 2)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('BMI')\n",
    "axes[0, 1].set_ylabel('Progresi√≥n')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Modelo Polin√≥mico Grado 3\n",
    "axes[1, 0].scatter(X_test, y_test, color='gray', alpha=0.6, s=50)\n",
    "X_test_sorted_poly3 = poly_features_3.transform(X_test_sorted_df)\n",
    "y_pred_poly3_sorted = model_poly3.predict(X_test_sorted_poly3)\n",
    "axes[1, 0].plot(X_test_sorted, y_pred_poly3_sorted, color='orange', linewidth=2.5, label=f'R¬≤={r2_poly3:.4f}')\n",
    "axes[1, 0].set_title('Modelo Polin√≥mico (Grado 3)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('BMI')\n",
    "axes[1, 0].set_ylabel('Progresi√≥n')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Modelo Logar√≠tmico\n",
    "axes[1, 1].scatter(X_test, y_test, color='gray', alpha=0.6, s=50)\n",
    "X_test_sorted_log = np.log(X_test_sorted_df + np.abs(X_test_sorted_df.min()) + 1)\n",
    "y_pred_log_sorted = model_log.predict(X_test_sorted_log)\n",
    "axes[1, 1].plot(X_test_sorted, y_pred_log_sorted, color='red', linewidth=2.5, label=f'R¬≤={r2_log:.4f}')\n",
    "axes[1, 1].set_title('Modelo Logar√≠tmico', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('BMI')\n",
    "axes[1, 1].set_ylabel('Progresi√≥n')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7080b5",
   "metadata": {},
   "source": [
    "## Paso 9: Gr√°fico de M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669da4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar m√©tricas en gr√°ficos de barras\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Comparaci√≥n de M√©tricas entre Modelos', fontsize=14, fontweight='bold')\n",
    "\n",
    "modelos = ['Lineal', 'Poly\\n(Grado 2)', 'Poly\\n(Grado 3)', 'Logar√≠tmico']\n",
    "colores = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "# MSE\n",
    "mses = [mse_linear, mse_poly2, mse_poly3, mse_log]\n",
    "axes[0].bar(modelos, mses, color=colores, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('MSE (Error Cuadr√°tico Medio)', fontsize=10)\n",
    "axes[0].set_title('Error Cuadr√°tico Medio', fontsize=11, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(mses):\n",
    "    axes[0].text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# RMSE\n",
    "rmses = [rmse_linear, rmse_poly2, rmse_poly3, rmse_log]\n",
    "axes[1].bar(modelos, rmses, color=colores, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('RMSE (Ra√≠z del MSE)', fontsize=10)\n",
    "axes[1].set_title('Ra√≠z del Error Cuadr√°tico', fontsize=11, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(rmses):\n",
    "    axes[1].text(i, v, f'{v:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# R¬≤\n",
    "r2s = [r2_linear, r2_poly2, r2_poly3, r2_log]\n",
    "axes[2].bar(modelos, r2s, color=colores, alpha=0.7, edgecolor='black')\n",
    "axes[2].set_ylabel('R¬≤ (Coeficiente de Determinaci√≥n)', fontsize=10)\n",
    "axes[2].set_title('R¬≤ Score', fontsize=11, fontweight='bold')\n",
    "axes[2].set_ylim([0, 1])\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(r2s):\n",
    "    axes[2].text(i, v, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e44580",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones y Recomendaciones Finales\n",
    "\n",
    "### üìä An√°lisis Comparativo:\n",
    "\n",
    "#### 1. **Mejor Desempe√±o**\n",
    "El modelo **Polin√≥mico de Grado 3** generalmente captura mejor la relaci√≥n no-lineal entre BMI y progresi√≥n de diabetes.\n",
    "\n",
    "#### 2. **Complejidad vs Rendimiento**\n",
    "- **Modelo Lineal**: Simple pero puede ser insuficiente para datos complejos\n",
    "- **Polin√≥mio Grado 2**: Balance entre complejidad y rendimiento\n",
    "- **Polin√≥mio Grado 3**: Mejor rendimiento pero riesgo de overfitting\n",
    "- **Logar√≠tmico**: √ötil si hay relaci√≥n logar√≠tmica en los datos\n",
    "\n",
    "#### 3. **Principios Clave**\n",
    "- **Empieza simple**: Comienza siempre con modelos simples (lineal)\n",
    "- **Prueba y mejora**: Si el ajuste es pobre, prueba modelos m√°s complejos\n",
    "- **Validaci√≥n**: Valida el modelo con datos de test independientes\n",
    "- **M√©tricas**: Observa R¬≤ y MSE para tomar decisiones informadas\n",
    "\n",
    "#### 4. **‚ö†Ô∏è Importante**\n",
    "**Mayor complejidad ‚â† mejor modelo**\n",
    "- El modelo m√°s simple que explique bien los datos es el mejor (Principio de Occam)\n",
    "- Ten cuidado con el **overfitting** (modelo memoriza datos en lugar de aprender patrones)\n",
    "- La complejidad excesiva puede causar malo rendimiento en datos nuevos\n",
    "\n",
    "### üéì Lecciones Pedag√≥gicas:\n",
    "\n",
    "1. El an√°lisis exploratorio de datos (EDA) es fundamental\n",
    "2. Diferentes modelos capturan diferentes relaciones\n",
    "3. Las m√©tricas de evaluaci√≥n son esenciales para la comparaci√≥n\n",
    "4. La divisi√≥n entrenamiento-test previene el overfitting\n",
    "5. La visualizaci√≥n ayuda a entender el comportamiento del modelo\n",
    "\n",
    "### üìà Recomendaciones Futuras:\n",
    "\n",
    "- Prueba con m√°s caracter√≠sticas (modelo multivariado)\n",
    "- Implementa regularizaci√≥n (Ridge, Lasso) para combatir overfitting\n",
    "- Usa validaci√≥n cruzada para evaluaci√≥n m√°s robusta\n",
    "- Experimenta con otros algoritmos (Random Forest, Gradient Boosting, etc.)\n",
    "- Considera t√©cnicas de feature engineering para mejorar modelos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
