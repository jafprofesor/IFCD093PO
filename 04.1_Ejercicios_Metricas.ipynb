{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d0e1d2",
   "metadata": {},
   "source": [
    "# 📊 EJERCICIOS PRÁCTICOS: Métricas de Evaluación en Machine Learning\n",
    "## Curso: Machine Learning con Python (IFCD093PO)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Objetivo\n",
    "\n",
    "En este notebook practicarás los conceptos aprendidos sobre **métricas de evaluación** tanto para problemas de **regresión** como de **clasificación**.\n",
    "\n",
    "### 📝 Instrucciones:\n",
    "\n",
    "1. **Lee cada ejercicio cuidadosamente**\n",
    "2. **Implementa el código** en las celdas señaladas con `# TODO:`\n",
    "3. **Ejecuta la celda** para verificar tus resultados\n",
    "4. **Compara con la solución** al final del notebook si tienes dudas\n",
    "\n",
    "### ⚠️ Importante:\n",
    "\n",
    "- **No hagas \"Ctrl+A\" para ver todo el código** - ¡aprenderás más escribiendo!\n",
    "- Si te atascas, consulta el notebook de teoría antes de mirar la solución\n",
    "- Intenta entender **por qué** cada métrica es útil, no solo cómo calcularla\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb88817",
   "metadata": {},
   "source": [
    "## 📦 Ejercicio 0: Importar Librerías\n",
    "\n",
    "Necesitaremos estas librerías para todos los ejercicios. Ejecuta la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d16490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn para datos y modelos\n",
    "from sklearn.datasets import load_diabetes, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Métricas para REGRESIÓN\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Métricas para CLASIFICACIÓN\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Configuración visual\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Todas las librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1968a4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PARTE 1: MÉTRICAS DE REGRESIÓN\n",
    "\n",
    "En estos ejercicios trabajaremos con un problema de **regresión** usando el dataset de Diabetes de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d592e",
   "metadata": {},
   "source": [
    "### Ejercicio 1.1: Cargar Datos y Entrenar Modelo de Regresión\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Carga el dataset de diabetes usando `load_diabetes(return_X_y=True)`\n",
    "2. Usa solo la primera característica (índice 0)\n",
    "3. Divide en train/test con `test_size=0.2` y `random_state=42`\n",
    "4. Entrena un modelo `LinearRegression()`\n",
    "5. Realiza predicciones en el conjunto de test\n",
    "\n",
    "**Pista:** Recuerda usar `X[:, np.newaxis, 0]` para seleccionar la primera característica con la dimensionalidad correcta.\n",
    "\n",
    "**Salida esperada:** Imprime las primeras 5 predicciones y los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 1.1 - Carga de datos y entrenamiento\n",
    "# 1. Carga el dataset de diabetes\n",
    "# X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# 2. Selecciona solo la primera característica (reshape para que sea 2D)\n",
    "# X_single = X[:, np.newaxis, 0]  # Selecciona la primera característica\n",
    "\n",
    "# 3. Divide en train/test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_single, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Entrena el modelo\n",
    "# modelo_regresion = LinearRegression()\n",
    "# modelo_regresion.fit(X_train, y_train)\n",
    "\n",
    "# 5. Realiza predicciones\n",
    "# y_pred = modelo_regresion.predict(X_test)\n",
    "\n",
    "# 6. Imprime resultados\n",
    "# print(f\"Primeras 5 predicciones: {y_pred[:5].round(2)}\")\n",
    "# print(f\"Primeros 5 valores reales: {y_test[:5].values}\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ef00b",
   "metadata": {},
   "source": [
    "### Ejercicio 1.2: Calcular MAE, MSE y RMSE\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Calcula el **Error Absoluto Medio (MAE)** usando `mean_absolute_error()`\n",
    "2. Calcula el **Error Cuadrático Medio (MSE)** usando `mean_squared_error()`\n",
    "3. Calcula el **RMSE** como la raíz cuadrada del MSE (usando `np.sqrt()`)\n",
    "\n",
    "**Pregunta:** ¿Cuál métrica crees que es más fácil de interpretar para un cliente? ¿Por qué?\n",
    "\n",
    "**Formato de salida:**\n",
    "```\n",
    "MAE: XX.XX\n",
    "MSE: XXXX.XX\n",
    "RMSE: XX.XX\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 1.2 - Calcular métricas de regresión\n",
    "\n",
    "# Calcula MAE\n",
    "mae = None  # mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calcula MSE\n",
    "mse = None  # mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcula RMSE\n",
    "rmse = None  # np.sqrt(mse)\n",
    "\n",
    "# Imprime los resultados\n",
    "# print(f\"MAE:  {mae:.2f}\")\n",
    "# print(f\"MSE:  {mse:.2f}\")\n",
    "# print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3752cf",
   "metadata": {},
   "source": [
    "### Ejercicio 1.3: Calcular y Interpretar R²\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Calcula el **Coeficiente de Determinación (R²)** usando `r2_score()`\n",
    "2. Interpreta el resultado respondiendo:\n",
    "   - ¿Qué porcentaje de la variabilidad explica el modelo?\n",
    "   - ¿Es un buen modelo? ¿Por qué?\n",
    "   - ¿Qué significaría un R² de 0? ¿Y de 1?\n",
    "\n",
    "**Salida esperada:**\n",
    "```\n",
    "R²: X.XX\n",
    "El modelo explica el XX% de la variabilidad en la variable objetivo.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3702c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 1.3 - Calcular R²\n",
    "\n",
    "# Calcula R²\n",
    "r2 = None  # r2_score(y_test, y_pred)\n",
    "\n",
    "# Imprime el resultado\n",
    "# print(f\"R²: {r2:.4f}\")\n",
    "# print(f\"El modelo explica el {r2*100:.1f}% de la variabilidad en la variable objetivo.\")\n",
    "\n",
    "# Crea un resumen\n",
    "# if r2 > 0.7:\n",
    "#     calidad = \"Excelente\"\n",
    "# elif r2 > 0.5:\n",
    "#     calidad = \"Bueno\"\n",
    "# elif r2 > 0.3:\n",
    "#     calidad = \"Aceptable\"\n",
    "# else:\n",
    "#     calidad = \"Pobre\"\n",
    "\n",
    "# print(f\"Calidad del modelo: {calidad}\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13105a28",
   "metadata": {},
   "source": [
    "### Ejercicio 1.4: Comparar Métricas - Análisis Completo\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Crea un diccionario con todas las métricas de regresión\n",
    "2. Crea una tabla (DataFrame) mostrando las métricas\n",
    "3. Escribe tu interpretación sobre qué tan bueno es el modelo\n",
    "\n",
    "**Formato esperado:**\n",
    "```\n",
    "Métricas de Evaluación - Modelo de Regresión\n",
    "┌─────────────────────┬──────────┐\n",
    "│ Métrica             │ Valor    │\n",
    "├─────────────────────┼──────────┤\n",
    "│ MAE (Error Medio)   │ XX.XX    │\n",
    "│ MSE (Error Cuadrát) │ XXXX.XX  │\n",
    "│ RMSE                │ XX.XX    │\n",
    "│ R² (Varianza Exp.)  │ X.XX     │\n",
    "└─────────────────────┴──────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ad63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 1.4 - Análisis completo de métricas\n",
    "\n",
    "# Crea un diccionario con todas las métricas\n",
    "metricas_regresion = {\n",
    "    # 'MAE': mae,\n",
    "    # 'MSE': mse,\n",
    "    # 'RMSE': rmse,\n",
    "    # 'R²': r2\n",
    "}\n",
    "\n",
    "# Crea un DataFrame\n",
    "# df_metricas = pd.DataFrame(list(metricas_regresion.items()), columns=['Métrica', 'Valor'])\n",
    "\n",
    "# Imprime la tabla\n",
    "# print(\"\\n📊 MÉTRICAS DE EVALUACIÓN - MODELO DE REGRESIÓN\")\n",
    "# print(df_metricas.to_string(index=False))\n",
    "\n",
    "# Escribe tu interpretación\n",
    "# print(\"\\n📝 INTERPRETACIÓN:\")\n",
    "# print(\"- El modelo se equivoca en promedio...\")\n",
    "# print(\"- Los errores grandes son...\")\n",
    "# print(\"- La capacidad explicativa del modelo es...\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bb739",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PARTE 2: MÉTRICAS DE CLASIFICACIÓN\n",
    "\n",
    "En estos ejercicios trabajaremos con un problema de **clasificación** usando el dataset de Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934a7d2",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: Cargar Datos y Entrenar Modelo de Clasificación\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Carga el dataset Iris usando `load_iris()`\n",
    "2. Extrae características (X) y objetivo (y) del dataset\n",
    "3. Convierte a problema binario: \"Iris Versicolor\" (clase 1) vs \"Otros\" (clase 0)\n",
    "4. Divide en train/test con `test_size=0.3` y `random_state=42`\n",
    "5. Entrena un modelo `LogisticRegression(random_state=42)`\n",
    "6. Realiza predicciones en el conjunto de test\n",
    "\n",
    "**Pista:** El dataset Iris tiene 3 clases (0=Setosa, 1=Versicolor, 2=Virginica). Para binario: `y_binary = (iris.target == 1).astype(int)`\n",
    "\n",
    "**Salida esperada:** Imprime estadísticas básicas del dataset binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 2.1 - Carga de datos de clasificación\n",
    "\n",
    "# 1. Carga el dataset Iris\n",
    "# iris = load_iris()\n",
    "# X_iris = iris.data\n",
    "# y_iris = iris.target\n",
    "\n",
    "# 2. Convierte a problema binario (Versicolor vs Otros)\n",
    "# y_binary = (y_iris == 1).astype(int)\n",
    "\n",
    "# 3. Divide en train/test\n",
    "# X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "#     X_iris, y_binary, test_size=0.3, random_state=42\n",
    "# )\n",
    "\n",
    "# 4. Entrena el modelo\n",
    "# modelo_clasificacion = LogisticRegression(random_state=42)\n",
    "# modelo_clasificacion.fit(X_train_c, y_train_c)\n",
    "\n",
    "# 5. Realiza predicciones\n",
    "# y_pred_c = modelo_clasificacion.predict(X_test_c)\n",
    "\n",
    "# 6. Imprime estadísticas\n",
    "# print(f\"Dataset Iris binario:\")\n",
    "# print(f\"  - Total de muestras: {len(y_binary)}\")\n",
    "# print(f\"  - Muestras positivas (Versicolor): {sum(y_binary)}\")\n",
    "# print(f\"  - Muestras negativas (Otros): {len(y_binary) - sum(y_binary)}\")\n",
    "# print(f\"  - Proporción: {sum(y_binary)/len(y_binary)*100:.1f}% positivas\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab76dbc",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Matriz de Confusión\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Calcula la **Matriz de Confusión** usando `confusion_matrix()`\n",
    "2. Extrae los valores: TP, TN, FP, FN\n",
    "3. Visualiza la matriz con un heatmap de Seaborn\n",
    "4. Escribe qué significan los números en tu contexto (Versicolor vs Otros)\n",
    "\n",
    "**Formato esperado:**\n",
    "```\n",
    "Matriz de Confusión:\n",
    "TN: XX  FP: X\n",
    "FN: X   TP: XX\n",
    "\n",
    "Interpretación:\n",
    "- Casos correctos: XX (negativo) + XX (positivo)\n",
    "- Casos incorrectos: X (falso positivo) + X (falso negativo)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14476f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 2.2 - Matriz de Confusión\n",
    "\n",
    "# 1. Calcula la matriz de confusión\n",
    "# cm = confusion_matrix(y_test_c, y_pred_c)\n",
    "\n",
    "# 2. Extrae los valores\n",
    "# tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# 3. Crea el heatmap\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=['No Versicolor', 'Versicolor'],\n",
    "#             yticklabels=['Real: No', 'Real: Sí'])\n",
    "# plt.title('Matriz de Confusión - Clasificador Iris')\n",
    "# plt.ylabel('Etiqueta Real')\n",
    "# plt.xlabel('Etiqueta Predicha')\n",
    "# plt.show()\n",
    "\n",
    "# 4. Imprime los valores\n",
    "# print(f\"\\nMatriz de Confusión:\")\n",
    "# print(f\"TN (Verdadero Negativo):  {tn}\")\n",
    "# print(f\"FP (Falso Positivo):      {fp}\")\n",
    "# print(f\"FN (Falso Negativo):      {fn}\")\n",
    "# print(f\"TP (Verdadero Positivo):  {tp}\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464ec3d",
   "metadata": {},
   "source": [
    "### Ejercicio 2.3: Calcular Accuracy, Precisión, Recall y F1-Score\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Calcula **Accuracy** usando `accuracy_score()`\n",
    "2. Calcula **Precisión** usando `precision_score()`\n",
    "3. Calcula **Recall** usando `recall_score()`\n",
    "4. Calcula **F1-Score** usando `f1_score()`\n",
    "5. Responde: ¿Qué significa cada métrica? ¿Cuál es la más importante para este problema?\n",
    "\n",
    "**Importante:** Usa `zero_division=0` para evitar advertencias.\n",
    "\n",
    "**Formato esperado:**\n",
    "```\n",
    "Accuracy:  X.XX (proporción de aciertos totales)\n",
    "Precisión: X.XX (exactitud de predicciones positivas)\n",
    "Recall:    X.XX (capacidad de detectar positivos)\n",
    "F1-Score:  X.XX (media armónica de precisión y recall)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 2.3 - Métricas de clasificación\n",
    "\n",
    "# Calcula Accuracy\n",
    "acc = None  # accuracy_score(y_test_c, y_pred_c)\n",
    "\n",
    "# Calcula Precisión\n",
    "prec = None  # precision_score(y_test_c, y_pred_c, zero_division=0)\n",
    "\n",
    "# Calcula Recall\n",
    "rec = None  # recall_score(y_test_c, y_pred_c, zero_division=0)\n",
    "\n",
    "# Calcula F1-Score\n",
    "f1 = None  # f1_score(y_test_c, y_pred_c, zero_division=0)\n",
    "\n",
    "# Imprime los resultados\n",
    "# print(f\"MÉTRICAS DE CLASIFICACIÓN:\")\n",
    "# print(f\"  Accuracy:   {acc:.4f} ({acc*100:.1f}%)\")\n",
    "# print(f\"  Precisión:  {prec:.4f} ({prec*100:.1f}%)\")\n",
    "# print(f\"  Recall:     {rec:.4f} ({rec*100:.1f}%)\")\n",
    "# print(f\"  F1-Score:   {f1:.4f}\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ef18e",
   "metadata": {},
   "source": [
    "### Ejercicio 2.4: Usar `classification_report`\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Usa `classification_report()` para obtener un reporte completo\n",
    "2. Imprime el reporte con nombres descriptivos: `target_names=['No Versicolor', 'Versicolor']`\n",
    "3. Usa `zero_division=0` para evitar advertencias\n",
    "4. Compara los valores con los que calculaste manualmente en el ejercicio 2.3\n",
    "\n",
    "**Salida esperada:** Reporte tabular con Precisión, Recall, F1-Score y Support por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639db8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 2.4 - Reporte de Clasificación\n",
    "\n",
    "# Obtén el reporte completo\n",
    "# reporte = classification_report(\n",
    "#     y_test_c, y_pred_c,\n",
    "#     target_names=['No Versicolor', 'Versicolor'],\n",
    "#     zero_division=0\n",
    "# )\n",
    "\n",
    "# Imprime el reporte\n",
    "# print(\"\\n📊 REPORTE DE CLASIFICACIÓN:\")\n",
    "# print(reporte)\n",
    "\n",
    "# Pregunta: ¿Los valores coinciden con el ejercicio 2.3?\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e83f98",
   "metadata": {},
   "source": [
    "### Ejercicio 2.5: Curva ROC y AUC\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Obtén las **probabilidades** de predicción usando `predict_proba()`\n",
    "2. Calcula la **curva ROC** usando `roc_curve()`\n",
    "3. Calcula el **AUC** usando `roc_auc_score()`\n",
    "4. Grafica la curva ROC con la línea de azar (diagonal)\n",
    "5. Interpreta: ¿Qué significa un AUC cercano a 1? ¿Y cercano a 0.5?\n",
    "\n",
    "**Pista:** Las probabilidades se obtienen de `modelo.predict_proba(X_test)[:, 1]` para la clase positiva.\n",
    "\n",
    "**Salida esperada:**\n",
    "```\n",
    "AUC: X.XX\n",
    "Curva ROC graficada con interpretación\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23300744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 2.5 - Curva ROC y AUC\n",
    "\n",
    "# 1. Obtén las probabilidades de la clase positiva\n",
    "# y_pred_proba = modelo_clasificacion.predict_proba(X_test_c)[:, 1]\n",
    "\n",
    "# 2. Calcula la curva ROC\n",
    "# fpr, tpr, thresholds = roc_curve(y_test_c, y_pred_proba)\n",
    "\n",
    "# 3. Calcula el AUC\n",
    "# auc = roc_auc_score(y_test_c, y_pred_proba)\n",
    "\n",
    "# 4. Grafica\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc:.2f})')\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Azar (AUC = 0.50)')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "# plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "# plt.title('Curva ROC')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.show()\n",
    "\n",
    "# 5. Interpreta\n",
    "# print(f\"\\nAUC: {auc:.2f}\")\n",
    "# if auc > 0.9:\n",
    "#     print(\"✅ Excelente clasificador (AUC > 0.9)\")\n",
    "# elif auc > 0.8:\n",
    "#     print(\"✅ Muy buen clasificador (AUC > 0.8)\")\n",
    "# elif auc > 0.7:\n",
    "#     print(\"✅ Buen clasificador (AUC > 0.7)\")\n",
    "# elif auc > 0.6:\n",
    "#     print(\"⚠️ Clasificador aceptable (AUC > 0.6)\")\n",
    "# else:\n",
    "#     print(\"❌ Clasificador pobre (AUC ≤ 0.6)\")\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca38a3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PARTE 3: ANÁLISIS Y COMPARACIÓN\n",
    "\n",
    "En estos ejercicios analizaremos cuándo usar cada métrica y cómo elegir la correcta para cada problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea15e4a",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: Crear Tabla Comparativa de Métricas\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Crea un DataFrame con todas las métricas de regresión de la Parte 1\n",
    "2. Crea un DataFrame con todas las métricas de clasificación de la Parte 2\n",
    "3. Compara: ¿Por qué no podemos usar métricas de regresión para clasificación y viceversa?\n",
    "\n",
    "**Formato esperado:**\n",
    "```\n",
    "REGRESIÓN:              CLASIFICACIÓN:\n",
    "Métrica      Valor      Métrica      Valor\n",
    "MAE          XX.XX      Accuracy     X.XX\n",
    "MSE          XXXX.XX    Precisión    X.XX\n",
    "RMSE         XX.XX      Recall       X.XX\n",
    "R²           X.XX       F1-Score     X.XX\n",
    "                        AUC          X.XX\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 3.1 - Tabla comparativa\n",
    "\n",
    "# Crea tabla de REGRESIÓN\n",
    "# df_reg = pd.DataFrame({\n",
    "#     'Métrica': ['MAE', 'MSE', 'RMSE', 'R²'],\n",
    "#     'Valor': [mae, mse, rmse, r2]\n",
    "# })\n",
    "\n",
    "# Crea tabla de CLASIFICACIÓN\n",
    "# df_clf = pd.DataFrame({\n",
    "#     'Métrica': ['Accuracy', 'Precisión', 'Recall', 'F1-Score', 'AUC'],\n",
    "#     'Valor': [acc, prec, rec, f1, auc]\n",
    "# })\n",
    "\n",
    "# Imprime ambas tablas\n",
    "# print(\"📊 REGRESIÓN vs CLASIFICACIÓN\\n\")\n",
    "# print(\"REGRESIÓN:\")\n",
    "# print(df_reg.to_string(index=False))\n",
    "# print(\"\\nCLASIFICACIÓN:\")\n",
    "# print(df_clf.to_string(index=False))\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4ef47",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Interpretación Crítica\n",
    "\n",
    "**Pregunta:** ¿Cuál es el propósito de evaluar un modelo? Responde brevemente (2-3 líneas):\n",
    "\n",
    "1. _________________________________\n",
    "2. _________________________________\n",
    "3. _________________________________\n",
    "\n",
    "**Pregunta:** ¿Por qué es peligroso usar una sola métrica para evaluar un modelo?\n",
    "\n",
    "Respuesta: ________________________________________________________________\n",
    "\n",
    "**Ejemplo:** Imagina un modelo que predice si alguien tiene cáncer. ¿Sería mejor tener:\n",
    "- ☐ Alta Precisión (los positivos que detecta son confiables)\n",
    "- ☐ Alto Recall (detecta todos los casos de cáncer, aunque haya falsos positivos)\n",
    "\n",
    "Justifica tu respuesta: _____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d2337",
   "metadata": {},
   "source": [
    "### Ejercicio 3.3: Visualización Comparativa de Todas las Métricas\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Crea una figura con 2 subplots:\n",
    "   - **Subplot 1:** Gráfico de barras con las métricas de regresión\n",
    "   - **Subplot 2:** Gráfico de barras con las métricas de clasificación\n",
    "2. Usa colores diferentes para distinguir tipos de problemas\n",
    "3. Añade títulos descriptivos\n",
    "\n",
    "**Hint:** Usa `fig, axes = plt.subplots(1, 2, figsize=(14, 5))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EJERCICIO 3.3 - Visualización comparativa\n",
    "\n",
    "# Crea figura con 2 subplots\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Subplot 1: Métricas de REGRESIÓN\n",
    "# metricas_reg = ['MAE', 'MSE', 'RMSE', 'R²']\n",
    "# valores_reg = [mae, mse, rmse, r2]\n",
    "# Nota: MSE y MAE están en escalas diferentes a RMSE y R², así que normaliza para visualizar\n",
    "\n",
    "# axes[0].bar(metricas_reg[:3], [mae, rmse, r2], color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "# axes[0].set_title('Métricas de Regresión', fontweight='bold')\n",
    "# axes[0].set_ylabel('Valor')\n",
    "# axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Subplot 2: Métricas de CLASIFICACIÓN\n",
    "# metricas_clf = ['Accuracy', 'Precisión', 'Recall', 'F1-Score', 'AUC']\n",
    "# valores_clf = [acc, prec, rec, f1, auc]\n",
    "\n",
    "# axes[1].bar(metricas_clf, valores_clf, color=['#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f'])\n",
    "# axes[1].set_title('Métricas de Clasificación', fontweight='bold')\n",
    "# axes[1].set_ylabel('Valor (0-1)')\n",
    "# axes[1].set_ylim([0, 1.1])\n",
    "# axes[1].grid(axis='y', alpha=0.3)\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"❌ Completa el código anterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606ca73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ SOLUCIONES\n",
    "\n",
    "Las soluciones están en las celdas siguientes. **Solo consulta si realmente te atascas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb497ba",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728384e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 1.1\n",
    "print(\"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 1.1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Carga el dataset de diabetes\n",
    "X_sol, y_sol = load_diabetes(return_X_y=True)\n",
    "\n",
    "# 2. Selecciona solo la primera característica (reshape para que sea 2D)\n",
    "X_single_sol = X_sol[:, np.newaxis, 0]  # Selecciona la primera característica\n",
    "\n",
    "# 3. Divide en train/test\n",
    "X_train_sol, X_test_sol, y_train_sol, y_test_sol = train_test_split(\n",
    "    X_single_sol, y_sol, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Entrena el modelo\n",
    "modelo_regresion_sol = LinearRegression()\n",
    "modelo_regresion_sol.fit(X_train_sol, y_train_sol)\n",
    "\n",
    "# 5. Realiza predicciones\n",
    "y_pred_sol = modelo_regresion_sol.predict(X_test_sol)\n",
    "\n",
    "# 6. Imprime resultados\n",
    "print(f\"\\nPrimeras 5 predicciones: {y_pred_sol[:5].round(2)}\")\n",
    "print(f\"Primeros 5 valores reales: {y_test_sol[:5].values}\")\n",
    "print(f\"\\nTamaño del conjunto de test: {len(X_test_sol)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b55460",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd54162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 1.2\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 1.2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcula MAE\n",
    "mae_sol = mean_absolute_error(y_test_sol, y_pred_sol)\n",
    "\n",
    "# Calcula MSE\n",
    "mse_sol = mean_squared_error(y_test_sol, y_pred_sol)\n",
    "\n",
    "# Calcula RMSE\n",
    "rmse_sol = np.sqrt(mse_sol)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"\\nMAE:  {mae_sol:.2f}\")\n",
    "print(f\"MSE:  {mse_sol:.2f}\")\n",
    "print(f\"RMSE: {rmse_sol:.2f}\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETACIÓN:\")\n",
    "print(f\"  • El modelo se equivoca en promedio {mae_sol:.2f} unidades (MAE)\")\n",
    "print(f\"  • El error cuadrático medio es {mse_sol:.2f}\")\n",
    "print(f\"  • El RMSE de {rmse_sol:.2f} es la métrica más interpretable (penaliza errores grandes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506656e",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 1.3\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 1.3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcula R²\n",
    "r2_sol = r2_score(y_test_sol, y_pred_sol)\n",
    "\n",
    "# Imprime el resultado\n",
    "print(f\"\\nR²: {r2_sol:.4f}\")\n",
    "print(f\"El modelo explica el {r2_sol*100:.1f}% de la variabilidad en la variable objetivo.\")\n",
    "\n",
    "# Crea un resumen\n",
    "if r2_sol > 0.7:\n",
    "    calidad = \"🟢 Excelente\"\n",
    "elif r2_sol > 0.5:\n",
    "    calidad = \"🟡 Bueno\"\n",
    "elif r2_sol > 0.3:\n",
    "    calidad = \"🟠 Aceptable\"\n",
    "else:\n",
    "    calidad = \"🔴 Pobre\"\n",
    "\n",
    "print(f\"Calidad del modelo: {calidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66412d",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 2.1\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 2.1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Carga el dataset Iris\n",
    "iris_sol = load_iris()\n",
    "X_iris_sol = iris_sol.data\n",
    "y_iris_sol = iris_sol.target\n",
    "\n",
    "# 2. Convierte a problema binario (Versicolor vs Otros)\n",
    "y_binary_sol = (y_iris_sol == 1).astype(int)\n",
    "\n",
    "# 3. Divide en train/test\n",
    "X_train_c_sol, X_test_c_sol, y_train_c_sol, y_test_c_sol = train_test_split(\n",
    "    X_iris_sol, y_binary_sol, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Entrena el modelo\n",
    "modelo_clasificacion_sol = LogisticRegression(random_state=42)\n",
    "modelo_clasificacion_sol.fit(X_train_c_sol, y_train_c_sol)\n",
    "\n",
    "# 5. Realiza predicciones\n",
    "y_pred_c_sol = modelo_clasificacion_sol.predict(X_test_c_sol)\n",
    "\n",
    "# 6. Imprime estadísticas\n",
    "print(f\"\\nDataset Iris binario:\")\n",
    "print(f\"  - Total de muestras: {len(y_binary_sol)}\")\n",
    "print(f\"  - Muestras positivas (Versicolor): {sum(y_binary_sol)}\")\n",
    "print(f\"  - Muestras negativas (Otros): {len(y_binary_sol) - sum(y_binary_sol)}\")\n",
    "print(f\"  - Proporción: {sum(y_binary_sol)/len(y_binary_sol)*100:.1f}% positivas\")\n",
    "print(f\"\\n  - Tamaño train: {len(X_train_c_sol)}\")\n",
    "print(f\"  - Tamaño test:  {len(X_test_c_sol)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7f95f",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29659fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 2.2\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 2.2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Calcula la matriz de confusión\n",
    "cm_sol = confusion_matrix(y_test_c_sol, y_pred_c_sol)\n",
    "\n",
    "# 2. Extrae los valores\n",
    "tn_sol, fp_sol, fn_sol, tp_sol = cm_sol.ravel()\n",
    "\n",
    "# 3. Crea el heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_sol, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Versicolor', 'Versicolor'],\n",
    "            yticklabels=['Real: No', 'Real: Sí'])\n",
    "plt.title('Matriz de Confusión - Clasificador Iris')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.show()\n",
    "\n",
    "# 4. Imprime los valores\n",
    "print(f\"\\nMatriz de Confusión:\")\n",
    "print(f\"TN (Verdadero Negativo):  {tn_sol}\")\n",
    "print(f\"FP (Falso Positivo):      {fp_sol}\")\n",
    "print(f\"FN (Falso Negativo):      {fn_sol}\")\n",
    "print(f\"TP (Verdadero Positivo):  {tp_sol}\")\n",
    "print(f\"\\nTotal de muestras: {tn_sol + fp_sol + fn_sol + tp_sol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eae661b",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 2.3\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 2.3\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcula Accuracy\n",
    "acc_sol = accuracy_score(y_test_c_sol, y_pred_c_sol)\n",
    "\n",
    "# Calcula Precisión\n",
    "prec_sol = precision_score(y_test_c_sol, y_pred_c_sol, zero_division=0)\n",
    "\n",
    "# Calcula Recall\n",
    "rec_sol = recall_score(y_test_c_sol, y_pred_c_sol, zero_division=0)\n",
    "\n",
    "# Calcula F1-Score\n",
    "f1_sol = f1_score(y_test_c_sol, y_pred_c_sol, zero_division=0)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"\\nMÉTRICAS DE CLASIFICACIÓN:\")\n",
    "print(f\"  Accuracy:   {acc_sol:.4f} ({acc_sol*100:.1f}%)\")\n",
    "print(f\"  Precisión:  {prec_sol:.4f} ({prec_sol*100:.1f}%)\")\n",
    "print(f\"  Recall:     {rec_sol:.4f} ({rec_sol*100:.1f}%)\")\n",
    "print(f\"  F1-Score:   {f1_sol:.4f}\")\n",
    "\n",
    "print(\"\\n💡 INTERPRETACIÓN:\")\n",
    "print(f\"  • Accuracy: {acc_sol*100:.1f}% de las predicciones fueron correctas\")\n",
    "print(f\"  • Precisión: De los {tp_sol + fp_sol} casos predichos como Versicolor, {tp_sol} fueron correctos\")\n",
    "print(f\"  • Recall: De los {tp_sol + fn_sol} Versicolores reales, {tp_sol} fueron detectados\")\n",
    "print(f\"  • F1-Score: Media armónica entre precisión y recall: {f1_sol:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9cc13",
   "metadata": {},
   "source": [
    "### SOLUCIÓN Ejercicio 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUCIÓN 2.5\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUCIÓN - EJERCICIO 2.5\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Obtén las probabilidades de la clase positiva\n",
    "y_pred_proba_sol = modelo_clasificacion_sol.predict_proba(X_test_c_sol)[:, 1]\n",
    "\n",
    "# 2. Calcula la curva ROC\n",
    "fpr_sol, tpr_sol, thresholds_sol = roc_curve(y_test_c_sol, y_pred_proba_sol)\n",
    "\n",
    "# 3. Calcula el AUC\n",
    "auc_sol = roc_auc_score(y_test_c_sol, y_pred_proba_sol)\n",
    "\n",
    "# 4. Grafica\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_sol, tpr_sol, color='darkorange', lw=2, label=f'Curva ROC (AUC = {auc_sol:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Azar (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 5. Interpreta\n",
    "print(f\"\\nAUC: {auc_sol:.2f}\")\n",
    "if auc_sol > 0.9:\n",
    "    print(\"✅ Excelente clasificador (AUC > 0.9)\")\n",
    "elif auc_sol > 0.8:\n",
    "    print(\"✅ Muy buen clasificador (AUC > 0.8)\")\n",
    "elif auc_sol > 0.7:\n",
    "    print(\"✅ Buen clasificador (AUC > 0.7)\")\n",
    "elif auc_sol > 0.6:\n",
    "    print(\"⚠️ Clasificador aceptable (AUC > 0.6)\")\n",
    "else:\n",
    "    print(\"❌ Clasificador pobre (AUC ≤ 0.6)\")\n",
    "\n",
    "print(f\"\\n💡 INTERPRETACIÓN:\")\n",
    "print(f\"El AUC de {auc_sol:.2f} significa que si elegimos aleatoriamente un ejemplo positivo y otro negativo,\")\n",
    "print(f\"hay un {auc_sol*100:.0f}% de probabilidad de que el modelo los ordene correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279bd40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 ¡Felicidades!\n",
    "\n",
    "Has completado todos los ejercicios prácticos sobre **Métricas de Evaluación**. \n",
    "\n",
    "### ✅ Lo que has practicado:\n",
    "\n",
    "- ✅ Cálculo de **MAE, MSE, RMSE y R²** para problemas de regresión\n",
    "- ✅ Construcción e interpretación de la **Matriz de Confusión**\n",
    "- ✅ Cálculo de **Accuracy, Precisión, Recall y F1-Score**\n",
    "- ✅ Generación de **Reportes de Clasificación** automatizados\n",
    "- ✅ Análisis de la **Curva ROC y AUC**\n",
    "- ✅ Decisión sobre **qué métrica usar** en cada contexto\n",
    "\n",
    "### 🚀 Próximos Pasos:\n",
    "\n",
    "1. **Revisa el notebook de teoría** si algún concepto sigue sin estar claro\n",
    "2. **Intenta ampliar los ejercicios** con otros datasets\n",
    "3. **Experimenta** cambiando parámetros de los modelos y observando cómo cambian las métricas\n",
    "4. **Prepárate para el próximo módulo**: Modelos Lineales (Regresión Logística)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
